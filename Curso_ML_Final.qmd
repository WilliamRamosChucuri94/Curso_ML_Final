---
title: "An√°lisis del Precio del Oro"
subtitle: "Direcci√≥n de Comercializaci√≥n de Oro ‚Äì BCE"
author: "Econ. William Ramos"
date: "`r Sys.Date()`"  
format:
  html:
    toc: true
    toc-depth: 3
    code-fold: true
    number-sections: true
    output-file: "index"
  docx: default
  pdf:
    toc: true
    number-sections: true
    df-print: kable
bibliography: referencias.bib
lang: es
params:
  fecha_corte: "2024-12-31"
---

------------------------------------------------------------------------

# **Unidad 1. Reporting con Quarto**

**¬øQu√© bases de datos vamos a utilizar?**

1.  Gold_Price
2.  Dollar Index
3.  Crude oild prices: West Texas Intermediate (WTI)
4.  Federal Founds Effective Rate
5.  Consumer Price Index for All Urban Consumer

**Comandos relevantes antes de iniciar**

‚Ä¢ **Ctrl+Shift+c=** Para comentar ‚Ä¢ **Ctrl+Shift+m =**Funci√≥n pipe %\>% √≥ \|\> ‚Äî‚ÄúConcatenar funciones‚Äù ‚Ä¢ **Atl+(-) =** asigno \<-

## ¬øQu√© es Quarto?

-   Plataforma de publicaci√≥n cient√≠fica

-   Compatible con R, Python, Julia, ObservableJS

-   Produce HTML, PDF, Word, presentaciones

-   Basado en Markdown + chunks de c√≥digo

## Librerias a utilizar

![](images/Librerias%20a%20instalar.png){fig-align="center" width="598"}

## ¬øQu√© es el YAML?

El encabezado en formato YAML (YAML Ain‚Äôt Markup Language) aparece al principio del documento de Quarto. Aunque es optativo, bajo ciertas circunstancias se genera autom√°ticamente durante el proceso de renderizado que genera el archivo de salida. Tanto el inicio como la finalizaci√≥n del encabezado YAML est√°n definidos por tres guiones aislados en una l√≠nea. La informaci√≥n contenida dentro de esas dos l√≠neas constituye el encabezado YAML. All√≠ suelen incluirse metadatos (tales como t√≠tulo, autor y fecha) y opciones generales que determinan la edici√≥n y las salidas (tales como el modo de edici√≥n predeterminado, el formato de salida y el tama√±o de las im√°genes).

![](images/YAML.png){fig-align="center"}

Este YAML configura **qu√© mostrar** (t√≠tulo, autor, subt√≠tulo, fecha), **c√≥mo mostrarlo** (HTML, PDF, Word con tablas de contenido, secciones numeradas, tablas bonitas) y permite incluir **bibliograf√≠a y par√°metros din√°micos**.

## Informaci√≥n general del documento

-   **title:** `"An√°lisis del Precio del Oro"`\
    ‚Üí El t√≠tulo principal del documento.

-   **subtitle:** `"Direcci√≥n de Comercializaci√≥n de Oro ‚Äì BCE"`\
    ‚Üí Subt√≠tulo que aparece debajo del t√≠tulo.

-   **author:** `"Econ. William Ramos"`\
    ‚Üí Autor o responsable del documento.

-   **date:** `` "`r Sys.Date()`" ``\
    ‚Üí Inserta la fecha del sistema de manera autom√°tica cuando se renderiza.\
    (Ejemplo: si hoy es 12/09/2025, el reporte saldr√° con esa fecha).

## Formatos de salida

Aqu√≠ defines a qu√© formatos se exportar√° el documento (HTML, Word, PDF) y con qu√© configuraciones.

**HTML**

-   **toc: true** ‚Üí agrega tabla de contenidos.

-   **toc-depth: 3** ‚Üí muestra hasta nivel 3 de t√≠tulos (`###`).

-   **code-fold: true** ‚Üí permite plegar/desplegar bloques de c√≥digo.

-   **number-sections: true** ‚Üí numera los t√≠tulos y secciones.

**docx**

Genera un archivo en Word con configuraci√≥n por defecto.

**PDF**

-   **toc: true** ‚Üí tabla de contenidos.

-   **number-sections: true** ‚Üí numeraci√≥n de secciones.

-   **df-print: kable** ‚Üí imprime tablas en formato `kable` (m√°s presentable en PDF).

**Bibliograf√≠a**

-   Apunta a un archivo **BibTeX (.bib)** con tus referencias.

-   Permite citar dentro del documento con `@Referencia`.

**Idioma**

Establece el idioma principal (afecta a etiquetas autom√°ticas como ‚ÄúTabla‚Äù, ‚ÄúFigura‚Äù, etc.).

**Par√°metros (params)**

-   Sirven para **pasar valores din√°micos** al documento.

-   Aqu√≠ defines `fecha_corte` como `"2024-12-31"`.

-   Luego lo puedes llamar en el texto con:

## Chunk setup

![](images/Chunk.png){fig-align="center" width="457"}

## Pr√°ctica de Quarto

**An√°lisis del oro**

El oro ha desempe√±ado hist√≥ricamente un papel central en la econom√≠a mundial, tanto como medio de intercambio en los sistemas monetarios cl√°sicos (patr√≥n oro), como en su funci√≥n contempor√°nea de activo refugio. A diferencia de otros metales, el oro no solo posee valor industrial o ornamental, sino que se ha consolidado como un instrumento financiero clave para preservar valor frente a la inflaci√≥n, la volatilidad cambiaria y la incertidumbre econ√≥mica.

En la actualidad, el an√°lisis del precio del oro se realiza desde m√∫ltiples perspectivas:

1.  **Econ√≥mica y macrofinanciera**:\
    Factores como la fortaleza del d√≥lar estadounidense, las tasas de inter√©s reales, la inflaci√≥n y la pol√≠tica monetaria de la Reserva Federal influyen directamente en la cotizaci√≥n del oro. Una depreciaci√≥n del d√≥lar o tasas de inter√©s bajas suelen impulsar la demanda del metal.

2.  **De mercado y de portafolio**:\
    Para los inversionistas, el oro act√∫a como un **activo diversificador**, ya que tiende a mostrar correlaciones negativas o d√©biles con otros activos de riesgo, como acciones y bonos. Esto lo convierte en una herramienta de cobertura (hedging) frente a escenarios adversos.

3.  **An√°lisis t√©cnico y de series temporales**:\
    Se utilizan m√©todos econom√©tricos (ARIMA, GARCH, VAR) y modelos m√°s recientes de *machine learning* (LSTM, random forests) para identificar patrones, volatilidad y posibles escenarios futuros del precio del oro.

4.  **Perspectiva estructural y geopol√≠tica**:\
    La oferta mundial de oro est√° determinada por la producci√≥n minera y el reciclaje, mientras que la demanda proviene de la joyer√≠a, la industria tecnol√≥gica, la inversi√≥n financiera y las compras de bancos centrales. A esto se suman factores de riesgo geopol√≠tico y crisis internacionales, que suelen incrementar la demanda del metal como refugio @ghule2022gold.

    Banco Central del Ecuador: [link](https://www.bce.fin.ec/estadisticas-economicas/)

![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRVeaZg1T6yBJG9Rl4P8MCkpv2QYV6pALqItQ&s){fig-align="center" width="150"}

**Par√°metros iniciales**

```{r, warning=FALSE, message=FALSE}


library(tidyverse)
library(gt)
library(quantmod)
library(tidyquant)
library(TTR)
library(zoo)
library(lubridate)

# Valor por defecto de params si alguien ejecuta sin YAML/CLI
if (!exists("params") || is.null(params$fecha_corte)) {
  params <- list(fecha_corte = "2024-12-31")
}

# Rutas candidatas (si este .qmd vive en reports/)
candidatas <- c("data/gold_dataset_monthly.rds",
                "../data/gold_dataset_monthly.rds",
                "../../data/gold_dataset_monthly.rds")
ruta <- candidatas[file.exists(candidatas)][1]
if (is.na(ruta)) stop("No se encontr√≥ gold_dataset_monthly.rds en data/, ../data/ o ../../data/")

d <- readr::read_rds(ruta)

# Aplicar par√°metro de fecha
fecha_corte <- as.Date(params$fecha_corte)
d <- d |> filter(date <= fecha_corte)

# Helper de formato
fmt_usd <- function(tbl, cols) {
  tbl |> fmt_currency(columns = {{ cols }}, currency = "USD")
}

# Helpers de formato (usa sep_mark en lugar de thousands_sep)
fmt_num <- function(tbl, columns, dec = 2) {
  gt::fmt_number(
    data     = tbl,
    columns  = {{ columns }},
    decimals = dec,
    dec_mark = ",",
    sep_mark = "."
  )
}

fmt_usd <- function(tbl, columns, dec = 2) {
  gt::fmt_currency(
    data     = tbl,
    columns  = {{ columns }},
    currency = "USD",
    decimals = dec,
    dec_mark = ",",
    sep_mark = "."
  )
}
```

**Primer cuadro**

```{r, warning=FALSE}
d |> select(date,GOLD) %>% 
  tail(12) %>% 
  gt() %>% 
  tab_header(title = "Oro: √∫ltimos 12 meses") %>% 
  fmt_usd(columns = GOLD)
```

## Gr√°fico

```{r}
d %>% 
  ggplot(aes(date,GOLD))+
  geom_line(linewidth=0.8)+
  labs(x=NULL, y= "USD/oz", title = "Evoluci√≥n mensual del precio del oro (USD)",
  subtitle= "2006-presente",
    caption="Fuente: Yahoo Finance")+
  theme_minimal()+
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 12, face = "italic"),
    plot.caption = element_text(hjust = 0.5, size = 9)
  )
```

**Tabla**

```{r}
d |> select(date,GOLD) %>% 
  tail(12) %>% 
  gt() %>% 
    cols_label(
      date="Fecha",
      GOLD="Precio Oro (USD)/oz"
    ) %>% 
  tab_header(title = "Oro: √∫ltimos 12 meses") %>% 
  fmt_usd(columns = GOLD) %>% 
  tab_source_note(
    source_note = "Fuente:FED"
  )
```

# **Unidad 2. Introducci√≥n a Machine Learning: Regresi√≥n Lineal**

![](images/Machine%20Learning_ML.png){fig-align="center" width="300"}

## Machine Learning

M√©todos que permiten que los sistemas aprendan patrones de datos

Diferencias con econometr√≠a tradicional:

-   ML enfatiza predicci√≥n, no solo inferencia causal

-   Maneja relaciones no lineales y alta dimensi√≥n

-   Aplicaciones en finanzas: precios, riesgo, trading.

    Jordan & Mitchell (2015), Science

**¬øEn donde podemos aplicar Machine Learning (ML)?**

-   El oro depende de m√∫ltiples variables: d√≥lar, petr√≥leo, tasas de inter√©s, inflaci√≥n

-   ML captura relaciones no lineales y complejas

## ¬øQu√© es modelar?

![](images/Que%20es%20modelar.png){fig-align="center"}

**Conceptos claves**

-   Unidad de an√°lisis

-   Set de entrenamiento (Utilizados para modelar)

-   Atributos

-   Variable dependiente, de respuesta o target (Valor predicho)

## Etapas de un problema de Machine Learning

![](images/Proceso%20ML.png){fig-align="center"}

## **Tipos de Machine Learning**

![](images/Tipos%20de%20Machine%20Learning.png){fig-align="center"}

**Fuente:** https://decidesoluciones.es/tipos-de-aprendizaje-algoritmos-machine-learning/

## 

An√°lisis Exploratorio de Datos (EDA)

-   Generar preguntas acerca de tus datos

-   Visualizaci√≥n, transformaci√≥n de datos

-   Vemos los aprendido y generamos nuevas preguntas

-   Conocer la base de datos

-   Distribuci√≥n de las variables

-   Presencia de valores perdidos

-   Outliers

-   Desbalance de clases, Etc

## M√©tricas de clasificaci√≥n

![](images/Matriz%20de%20confusion.png){fig-align="center" width="566"}

## Tidymodels

![](images/TIDYMODELS.png){fig-align="center" width="560"}

Fuente: https://www.tidymodels.org/

## 

Flujo de trabajo

-   Partici√≥n de datos ‚Üí rsample

-   Ingenier√≠a de variables ‚Üí recipes

-   Especificaci√≥n de modelos ‚Üí parsnip

-   Integraci√≥n pipeline ‚Üí workflows

-   Evaluaci√≥n ‚Üí yardstick

## Recipes (Feature Engineering)

-   Preprocesamiento de datos antes de modelar

-   Escalamiento y normalizaci√≥n

-   Creaci√≥n de nuevas variables

-   Manejo de outliers y NA

-   Reducci√≥n de colinealidad

Ejemplo: step_normalize(), step_corr()

## **Parsnip (Ajuste de modelos)**

-   Interfaz unificada para modelos ML

-   Especificaci√≥n: linear_reg()

-   Motores: lm, glmnet, xgboost Ejemplo: mod \<- linear_reg() \|\> set_engine('lm')

## **Yardstick (M√©tricas de Ajuste)**

-   Evaluaci√≥n de modelos.

-   M√©tricas principales: RMSE ‚Äì Error cuadr√°tico medio MAE ‚Äì Error absoluto medio R¬≤ ‚Äì Varianza explicada

-   Comparaci√≥n de modelos con m√©tricas comunes.

## Comentarios Finales

-   ML complementa la econometr√≠a

-   √ötil cuando hay muchas variables

-   Relaci√≥n no lineal o compleja

-   Usos BCE: predicci√≥n de oro, inflaci√≥n, riesgo financiero

# **Unidad 3. Creaci√≥n de un flujo de trabajo de Machine Learning (ML)**

## Introducci√≥n a la regresi√≥n lineal en R-lm

La regresi√≥n lineal es un modelo estad√≠stico y de machine learning supervisado que se utiliza para explicar y predecir una variable dependiente (tambi√©n llamada variable respuesta o ***Y***) a partir de una o varias variables independientes (tambi√©n llamadas regresores, predictores o ***X***).

La idea central es ajustar una l√≠nea recta (o hiperplano en dimensiones mayores) que relacione los valores de ***X*** con los de ***Y***, minimizando la diferencia entre los valores observados y los predichos.

**Forma matem√°tica**

Para una **regresi√≥n lineal simple** (con una sola variable (X)):

$Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i$

-   $Y_i$: Variable dependiente (lo que queremos explicar).\
-   $X_i$: Variable independiente (el predictor).\
-   $\beta_0$: Intercepto (valor de $Y$ cuando $X=0$).\
-   $\beta_1$: Pendiente (cambio promedio en $Y$ por cada unidad adicional de $X$).\
-   $\varepsilon_i$: t√©rmino de error (factores no observados).

------------------------------------------------------------------------

En la **regresi√≥n m√∫ltiple** (con varios predictores):

$Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \dots + \beta_k X_{ki} + \varepsilon_i$

**¬øC√≥mo se estima?**

Se utiliza el m√©todo de M√≠nimos Cuadrados Ordinarios (MCO / OLS, por sus siglas en ingl√©s), que busca los valores de los coeficiente que minimizan la suma de los errores al cuadrado:

$\min_{\beta} \sum_{i=1}^{n} (Y_i - \hat{Y}_i)^2$

**Interpretaci√≥n**

-   El modelo explica la relaci√≥n promedio lineal entre $Y$ y las variables $X$.

-   Los coeficientes \$\\beta\$ representan el efecto marginal de cada variable independiente sobre $Y$,manteniendo las dem√°s constante.

-   El $R^2$ mide el porcentaje de la variabilidad de $Y$ explicado por el modelo.

    **Ejemplo intuitivo**

    Si $Y$= **ingreso mensual** y $X$ **a√±os de educaci√≥n**

    $Ingreso$ = $\beta_0$+$\beta_1$x $Educaci√≥n$+$\varepsilon_i$

-   $\beta_0$: Ingreso esperado si la educaci√≥n = $0$

-   $\beta_1$: Cuanto aumenta (en promedio) el ingreso por cada a√±o adicional de educaci√≥n.

**En Resumen**

-   Un modelo estad√≠stico y predictivo.

-   Busca una relaci√≥n lineal entre variables

-   Se estima normalmente con m√≠nimos cuadrados.

-   Es una de las herramientas m√°s usadas en estad√≠stica, econometr√≠a y machine learning.

**¬°Vamos a la practica!**

**Observamos la gr√°fica del oro**

```{r}
plot(d$date, d$GOLD, 
     type = "l",          # "l" = line
     col = "blue", 
     lwd = 2,             # grosor de la l√≠nea
     xlab = "Fecha", 
     ylab = "Valor Oro en niveles", 
     main = "Evoluci√≥n del oro en niveles")
```

**Observamos la gr√°fica del d√≥lar**

```{r}
plot(d$date, d$DOLLAR, 
     type = "l",          # "l" = line
     col = "blue", 
     lwd = 2,             # grosor de la l√≠nea
     xlab = "Fecha", 
     ylab = "Dolar en niveles", 
     main = "Evoluci√≥n del d√≥lar en niveles")
```

**Retornos en gr√°ficos: Oro**

```{r}
plot(d$date, d$gold_ret, 
     type = "l",          # "l" = line
     col = "blue", 
     lwd = 2,             # grosor de la l√≠nea
     xlab = "Fecha", 
     ylab = "Retorno del oro", 
     main = "Evoluci√≥n del retorno del oro")
```

**Retornos en gr√°ficos: Dolar**

```{r}
plot(d$date, d$dollar_ret, 
     type = "l",          # "l" = line
     col = "blue", 
     lwd = 2,             # grosor de la l√≠nea
     xlab = "Fecha", 
     ylab = "Retorno del d√≥lar", 
     main = "Evoluci√≥n del retorno del d√≥lar")
```

```{r}
s1 <- d |>
  select(date, gold_ret, dollar_ret) |>
  drop_na()
print(s1)
```

```{r}
regresion <- lm(gold_ret ~ dollar_ret, data = s1)
summary(regresion)
```

**Interpretemos**

$$
gold\_ret_{t} = 0.006652 - 1.0913 \cdot dollar\_ret_{t} + \varepsilon_{t}
$$

**Coeficientes**

-   Intercepto: $(0.006652,\; p=0.019)$

-   Cuando el retorno del d√≥lar es cero, el retorno promedio del oro es aproximadamente $0.66\%$.\
    Es significativo al $5\%$ ($p < 0.05$).

-   Pediente: $(-1.0913,\; p < 0.001)$

-   Por cada incremento de $1$ unidad en el retorno del d√≥lar, el retorno del oro disminuye en promedio $1.09$ unidades.\
    Es altamente significativo ($p \approx 0.000000425$).\
    El signo negativo confirma la teor√≠a: la apreciaci√≥n del d√≥lar tiende a reducir el precio del oro.

**Coeficientes**

**Intercepto** $(0.006652,\; p=0.019)$

Cuando el retorno del d√≥lar es cero:

$$
\hat{Y} = 0.006652
$$

El retorno promedio del oro es ‚âà $0.66\%$.\
Es significativo al $5\%$ ($p < 0.05$).

------------------------------------------------------------------------

**Pendiente** $(-1.0913,\; p < 0.001)$

Por cada incremento de $1$ unidad en el retorno del d√≥lar:

$$
\Delta gold\_ret = -1.0913 \cdot \Delta dollar\_ret
$$

El retorno del oro disminuye en promedio $1.09$ unidades.\
Es altamente significativo ($p \approx 0.000000425$).\
El signo negativo confirma la teor√≠a: la apreciaci√≥n del d√≥lar tiende a reducir el precio del oro.

------------------------------------------------------------------------

üîπ **Bondad de ajuste**

$$
R^2 = 0.1612 \quad (16.1\%)
$$

El modelo explica solo un $16\%$ de la variaci√≥n en el retorno del oro.\
Esto es com√∫n en series financieras: el oro depende de m√∫ltiples factores, no solo del d√≥lar.

$$
R^2_{ajustado} = 0.155
$$

Confirma que la complejidad no a√±ade mucha p√©rdida.

Error est√°ndar residual:

$$
\sigma_{\hat{\varepsilon}} = 0.03408
$$

En promedio, los residuos (errores) son de $3.4$ puntos porcentuales.

------------------------------------------------------------------------

üîπ **Pruebas de significancia global**

$$
F = 28.06, \quad p < 0.001
$$

El modelo en su conjunto es estad√≠sticamente significativo.\
Al menos un coeficiente (aqu√≠ $\beta_1$) difiere de cero.

------------------------------------------------------------------------

üîπ Resumen interpretativo

-   **Direcci√≥n:** relaci√≥n negativa clara entre d√≥lar y oro.\
-   **Magnitud:** movimientos del d√≥lar tienen un efecto importante en el oro.\
-   **Significancia:** el efecto es estad√≠sticamente robusto.\
-   **Limitaci√≥n:** el modelo explica solo una fracci√≥n peque√±a de la variaci√≥n ($16\%$).

------------------------------------------------------------------------

üìä **Conclusi√≥n**

La regresi√≥n simple muestra evidencia s√≥lida de que el d√≥lar influye en el oro de forma negativa.\
Sin embargo, la baja capacidad predictiva ($R^2$ bajo) implica que se necesitan otros factores (petr√≥leo, tasas de inter√©s, inflaci√≥n, shocks geopol√≠ticos) para construir un modelo predictivo m√°s fuerte.

**Cuadro resumen**

```{r}
library(gt)
#| label: simple-lm
lm_s <- lm(gold_ret ~ dollar_ret, data = s1)
broom::tidy(lm_s, conf.int = TRUE) |>
  gt() |>
  tab_header(title = "OLS (simple): coeficientes e IC 95%") |>
  fmt_num(c(estimate, std.error, statistic, p.value, conf.low, conf.high), dec = 6)

```

**Un cuadro mas completo**

```{r}
library(gt)

resumen <- broom::tidy(lm_s, conf.int = TRUE) |>
  mutate(
    sig = case_when(
      p.value < 0.01 ~ "***",
      p.value < 0.05 ~ "**",
      p.value < 0.1  ~ "*",
      TRUE ~ ""
    ),
    interpretacion = c(
      "Cuando el retorno del d√≥lar es 0, el oro sube ‚âà 0.66% en promedio",
      "Un aumento de 1% en el retorno del d√≥lar reduce el retorno del oro en ‚âà 1.09%"
    )
  )

gt(resumen) |>
  fmt_number(columns = c(estimate, std.error, statistic, p.value, conf.low, conf.high),
             decimals = 6, dec_mark = ",", sep_mark = ".") |>
  tab_header(title = "OLS (simple): coeficientes e interpretaci√≥n") |>
  cols_label(
    term = "Variable",
    estimate = "Estimador",
    std.error = "Error Est.",
    statistic = "t",
    p.value = "p-valor",
    conf.low = "IC 95% (Inf)",
    conf.high = "IC 95% (Sup)",
    sig = "Sig.",
    interpretacion = "Interpretaci√≥n"
  )

```

**¬øC√≥mo se ve gr√°ficamente esta relaci√≥n lineal?**

```{r}
# Gr√°fico de dispersi√≥n correcto
plot(d$dollar_ret, d$gold_ret,
     main = "Regresi√≥n lineal: Oro vs D√≥lar",
     xlab = "Rendimiento del d√≥lar",
     ylab = "Rendimiento del oro",
     pch = 19, col = "darkgray")

# Modelo consistente
modelo <- lm(gold_ret ~ dollar_ret, data = d)

# L√≠nea de regresi√≥n
abline(modelo, col = "blue", lwd = 2)


```

**Gr√°fico con ggplot**

```{r, warning=FALSE, message=FALSE}
s1 |> ggplot(aes(dollar_ret, gold_ret)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = TRUE, linewidth = 0.9) +
  labs(x = "Retorno del D√≥lar (DXY)", y = "Retorno del Oro", title = "Regresi√≥n lineal simple") +
  theme_minimal()

```

**Diagnostico predictivo inicial**

```{r}
library(broom)
library(gt)

# Ajuste del modelo
lm_s <- lm(gold_ret ~ dollar_ret, data = d)

# Resumen del modelo
glance_tbl <- broom::glance(lm_s)

# Tabla con formateo
glance_tbl %>%
  gt() %>%
  tab_header(title = "Diagn√≥stico global (R¬≤, F, œÉ, AIC/BIC)") %>%
  fmt_number(
    columns = c(r.squared, adj.r.squared, sigma, statistic, p.value, AIC, BIC, logLik, deviance),
    decimals = 6,
    dec_mark = ",",
    sep_mark = "."
  )

```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
tabla <- data.frame(
  Estad√≠stico = c("R¬≤", "R¬≤ ajustado", "œÉ (residual standard error)", 
                  "F (statistic)", "p-value (modelo)", 
                  "df (grados de libertad regresor)", "df.residual", "nobs",
                  "LogLik", "AIC", "BIC", "Deviance"),
  Valor = c(0.161, 0.155, 0.0341, 28.06, "< 0.0001", 
            1, 146, 148, 291.08, -576.16, -567.17, 0.1696),
  Interpretaci√≥n = c(
    "El modelo explica el 16.1% de la variaci√≥n en el retorno del oro a partir del retorno del d√≥lar.",
    "Similar al R¬≤, ajusta por el n√∫mero de predictores. Confirma que el modelo no est√° sobreajustado.",
    "El error t√≠pico de los residuos es ‚âà 3.4 puntos porcentuales en los retornos del oro. Indica la magnitud del error de predicci√≥n.",
    "Prueba de significancia global: el modelo como conjunto es significativo.",
    "Muy fuerte evidencia de que al menos un coeficiente (el retorno del d√≥lar) explica parte de la variaci√≥n en el oro.",
    "Solo hay un predictor (dollar_ret).",
    "Grados de libertad de los residuos (n - k - 1).",
    "Observaciones efectivas utilizadas.",
    "Valor de la funci√≥n de verosimilitud. Base para comparar modelos.",
    "Criterio de Akaike: m√°s bajo indica mejor ajuste relativo.",
    "Criterio de Bayes: penaliza m√°s por complejidad, √∫til en comparaci√≥n de modelos.",
    "Suma de residuos al cuadrado (varianza no explicada)."
  )
)

gt(tabla)

```

## Supuestos de OLS y diagn√≥sticos

-   **Linealidad**: Este supuesto implica que la relaci√≥n entre las variables independientes y la variable dependiente debe ser lineal. Si la relaci√≥n es no lineal, los resultados de la regresi√≥n (lineal) pueden ser poco confiables y conducir a interpretaciones err√≥neas sobre la relaci√≥n entre las variables.

-   **Normalidad**: El supuesto de normalidad establece que los **errores** de la regresi√≥n deben seguir una distribuci√≥n normal. ¬°Cuidado con esto!, los errores, no las variables. Cuando este supuesto se cumple, las pruebas de hip√≥tesis y los intervalos de confianza pueden interpretarse con mayor precisi√≥n. Si la normalidad no se cumple, los intervalos de confianza y las pruebas de hip√≥tesis pueden verse afectados, lo que puede conducir a conclusiones err√≥neas.

-   **Homocedasticidad**: Este supuesto implica que la varianza de los **errores** debe ser constante en todos los niveles de las variables predictoras. Cuando se viola este supuesto, se produce **heterocedasticidad**, lo que significa que la dispersi√≥n de los errores var√≠a en diferentes rangos de las variables predictoras. La presencia de heterocedasticidad puede distorsionar los intervalos de confianza y los valores p-value, lo que puede afectar la precisi√≥n de las pruebas de hip√≥tesis.

-   **Independencia**: El supuesto de independencia indica que los errores de la regresi√≥n no deben estar correlacionados entre s√≠. Si hay autocorrelaci√≥n presente, puede afectar la precisi√≥n de los coeficientes y las pruebas de hip√≥tesis, lo que lleva a conclusiones err√≥neas sobre la importancia de las variables predictoras. **¬øQu√© es la autocorrelaci√≥n?** la presencia de autocorrelaci√≥n en los residuos indica que **los errores del modelo muestran cierto patr√≥n sistem√°tico en su distribuci√≥n a lo largo del tiempo**. Recordad que los errores o residuos de un modelo de regresi√≥n deber√≠an distribuirse de manera aleatoria y seguir una distribuci√≥n normal con media cero y varianza constante.

```{r}
#| label: diag-plots
#| fig-cap: "Residuos vs ajustados (homocedasticidad y forma)"
aug <- broom::augment(lm_s)
aug |>
  ggplot(aes(.fitted, .resid)) +
  geom_hline(yintercept = 0, linetype = 2, color="gray50") +
  geom_point(alpha = 0.6) +
  labs(x="Ajustados", y="Residuos") + theme_minimal()

```

## 1. Gr√°fico de **Residuos vs. Ajustados**

-   **Qu√© muestra**:

    -   En el eje X est√°n los valores ajustados (predichos por el modelo)

        En el eje Y est√°n los residuos (diferencia entre observado y predicho).

    **Interpretaci√≥n**:

    -   La nube de puntos parece estar dispersa alrededor de la l√≠nea horizontal 0, sin un patr√≥n claro.

        Esto es bueno: sugiere que **no hay heterocedasticidad fuerte ni relaci√≥n sistem√°tica no captada por el modelo**.

        Si vieras una forma de ‚Äúabanico‚Äù (residuos m√°s grandes a medida que crece el ajustado) o una curva, eso indicar√≠a problemas como heterocedasticidad o falta de linealidad.

    -   **Uso en clase**: sirve para explicar la verificaci√≥n de dos supuestos:

    -   La varianza constante de los errores (homocedasticidad).

        Que el modelo capta la relaci√≥n lineal y no deja un patr√≥n estructurado en los residuos.

```{r}
#| label: diag-qq
#| fig-cap: "Normalidad: Q‚ÄìQ plot"
qq <- qqnorm(resid(lm_s), plot.it = FALSE)
tibble(x = qq$x, y = qq$y) |>
  ggplot(aes(x, y)) +
  geom_abline(slope = 1, intercept = 0, color="gray50") +
  geom_point(alpha = 0.6) + theme_minimal() +
  labs(x="Te√≥rico", y="Muestral")

```

-   Compara la distribuci√≥n de los residuos del modelo con la distribuci√≥n normal te√≥rica.

-   La mayor√≠a de los puntos sigue la l√≠nea diagonal gris, lo que indica que los residuos son **aproximadamente normales**.

```{r}
#| label: tests
# Pruebas formales
dw <- lmtest::dwtest(lm_s)      # autocorrelaci√≥n
bp <- lmtest::bptest(lm_s)      # heterocedasticidad (Breusch‚ÄìPagan)
sh <- shapiro.test(resid(lm_s)) # normalidad (muestras peque√±as)

tibble(
  prueba = c("Durbin‚ÄìWatson", "Breusch‚ÄìPagan", "Shapiro‚ÄìWilk"),
  estadistico = c(dw$statistic, bp$statistic, sh$statistic),
  p_value     = c(dw$p.value, bp$p.value, sh$p.value)
) |>
  gt() |> tab_header(title = "Pruebas de supuestos (simple)") |>
  fmt_num(c(estadistico, p_value), dec = 6)
d
```

**Durbin Watson**

-   **Hip√≥tesis**

-   Ho: No hay autocorrelaci√≥n en los residuos

-   H1: Existe autocorrelaci√≥n (+ o -)

-   El estad√≠stico DW ‚âà 2 (ideal, indica independencia).

-   Como p-valor \> 0.05, **no rechazamos H‚ÇÄ** ‚Üí no hay evidencia de autocorrelaci√≥n en los residuos.

**Breusch‚ÄìPagan**

-   Ho: Los residuos son homoced√°sticos (varianza constante)

-   H1: Los residuos son heteroced√°sticos (varianza no constante)

-   p-valor \> 0.05, **no rechazamos H‚ÇÄ** ‚Üí no hay evidencia de heterocedasticidad significativa.

**Shapiro‚ÄìWilk (normalidad de residuos)**

-   Ho: Los residuos siguen una distribuci√≥n normal

-   H1: Los residuos no siguen una distribuci√≥n normal

-   p-valor \> 0.05, **no rechazamos H‚ÇÄ** ‚Üí los residuos pueden considerarse aproximadamente normales.

    **Comentario**

-   En series de tiempo, la autocorrelaci√≥n y heterocedasticidad son frecuentes. Lo importante es reportarlo y pasar a un flujo robusto fuera de muestra.

## An√°lisis Eploratorio de Datos (EDA)

```{r, message=FALSE, warning=FALSE}
library(tidymodels)
library(tidyverse)
library(skimr)
library(DataExplorer)
library(ggpubr)
library(univariateML)
library(GGally)
library(doParallel)
skim(d)
```

**Datos faltantes**

```{r, message=FALSE, warning=FALSE}
d %>% map_dbl(.f = function(x){sum(is.na(x))})
```

**Missing data**

```{r, message=FALSE, warning=FALSE}
plot_missing(
  data    = d, 
  title   = "Porcentaje de valores ausentes",
  ggtheme = theme_bw(),
  theme_config = list(legend.position = "none")
)
```

**Distribuci√≥n o Densidad**

```{r, message=FALSE, warning=FALSE}
p1 <- ggplot(data = d, aes(x = GOLD)) +
      geom_density(fill = "steelblue", alpha = 0.8) +
      geom_rug(alpha = 0.1) +
      scale_x_continuous(labels = scales::comma) +
      labs(title = "Distribuci√≥n original") +
      theme_bw() 

p2 <- ggplot(data = d, aes(x = sqrt(GOLD))) +
      geom_density(fill = "steelblue", alpha = 0.8) +
      geom_rug(alpha = 0.1) +
      scale_x_continuous(labels = scales::comma) +
      labs(title = "Transformaci√≥n ra√≠z cuadrada") +
      theme_bw()

p3 <- ggplot(data = d, aes(x = log(GOLD))) +
      geom_density(fill = "steelblue", alpha = 0.8) +
      geom_rug(alpha = 0.1) +
      scale_x_continuous(labels = scales::comma) +
      labs(title = "Transformaci√≥n logar√≠tmica") +
      theme_bw() 

ggarrange(p1, p2, p3, ncol = 1, align = "v")
```

**Varible ret**

```{r, message=FALSE, warning=FALSE}

p1 <- ggplot(data = d, aes(x = gold_ret)) +
      geom_density(fill = "steelblue", alpha = 0.8) +
      geom_rug(alpha = 0.1) +
      scale_x_continuous(labels = scales::comma) +
      labs(title = "Distribuci√≥n original") +
      theme_bw() 

p2 <- ggplot(data = d, aes(x = sqrt(gold_ret))) +
      geom_density(fill = "steelblue", alpha = 0.8) +
      geom_rug(alpha = 0.1) +
      scale_x_continuous(labels = scales::comma) +
      labs(title = "Transformaci√≥n ra√≠z cuadrada") +
      theme_bw()

p3 <- ggplot(data = d, aes(x = log(gold_ret))) +
      geom_density(fill = "steelblue", alpha = 0.8) +
      geom_rug(alpha = 0.1) +
      scale_x_continuous(labels = scales::comma) +
      labs(title = "Transformaci√≥n logar√≠tmica") +
      theme_bw() 

ggarrange(p1, p2, p3, ncol = 1, align = "v")
```

**Distribuci√≥n de variables continuas**

```{r, message=FALSE, warning=FALSE}
plot_density(
  data    = d %>% select(-up_next),
  ncol    = 3,
  title   = "Distribuci√≥n variables continuas",
  ggtheme = theme_bw(),
  theme_config = list(
                  plot.title = element_text(size = 16, face = "bold"),
                  strip.text = element_text(colour = "black", size = 12, face = 2)
                 )
  )
```

**Plot de variables cualitativas**

```{r, message=FALSE, warning=FALSE}
plot_bar(
  d,
  ncol    = 3,
  title   = "N√∫mero de observaciones por grupo",
  ggtheme = theme_bw(),
  theme_config = list(
                   plot.title = element_text(size = 16, face = "bold"),
                   strip.text = element_text(colour = "black", size = 12, face = 2),
                   legend.position = "none"
                  )
)
```

```{r, message=FALSE, warning=FALSE}
#| label: eda
eda <- d |>
  select(gold_next_ret, dollar_ret, wti_ret, infl_yoy, ma6, ma12, rsi14) |>
  drop_na()

cor(eda, use="pairwise.complete.obs") |>
  as.data.frame() |> rownames_to_column("var") |> as_tibble() |>
  gt() |> tab_header(title="Correlaciones (Pearson)") |> fmt_num(everything(), dec=3)
```

-   El **√∫nico predictor con cierta fuerza lineal sobre el oro** es el **d√≥lar** (negativo, -0.24).

    Los dem√°es (petr√≥lo, inflaci√≥n, medias m√≥viles, RSI) muestran correlaciones d√©biles con los rendimientos inmediatos del oro.

    Existe **multicolinealidad esperada entre medias m√≥viles** (ma6 y ma12), lo que hay que cuidar si se meten juntas en un modelo.

    **Indicadores t√©cnicos (ma, rsi)** est√°n m√°s relacionados entre s√≠ que con el oro, lo cual tiene sentido porque son derivados de los mismos precios.

# **Tidymodels**

![](images/Captura%20de%20pantalla%202025-09-10%20124819.png){fig-align="center"}

# **Preprocesamiento**

**rsample:** Creamos una divisi√≥n entre train y test

## Partici√≥n temporal y feature engineering (Recipes)

```{r, warning=FALSE, message=FALSE}
library(rsample)
library(recipes)

set.seed(123)
datos <- d |>
  select(date, gold_next_ret, dollar_ret, wti_ret, infl_yoy, ma6, ma12, rsi14) |>
  drop_na()

split <- initial_time_split(datos, prop = 0.80)
train <- training(split); test <- testing(split)

tibble(n_train=nrow(train), n_test=nrow(test),
       min_train=min(train$date), max_train=max(train$date),
       min_test=min(test$date),   max_test=max(test$date)) |>
  gt() |> tab_header(title="Partici√≥n temporal")

```

```{r, message=FALSE, warning=FALSE}
print (split)
```

```{r, message=FALSE, warning=FALSE}
library(recipes)
#| label: recipe
rec <- recipes::recipe(gold_next_ret ~ dollar_ret + wti_ret + infl_yoy + ma6 + ma12 + rsi14, data=train) |>
  step_zv(all_predictors()) |>
  step_normalize(all_numeric_predictors()) |>
  step_corr(all_numeric_predictors(), threshold = 0.95)

prep(rec)  # mostrar√° qu√© variables elimina por colinealidad (p.ej. ma12)


```

-   **Inputs**

    1 variable objetivo (`gold_next_ret`) y 6 predictores (los listados)

    **Training information**

    -   La receta ‚Äúaprendi√≥‚Äù usando **118 observaciones** de `train` y no encontr√≥ filas incompletas

    **Operations**

    -   **Zero variance**: no se elimin√≥ ninguna ( `<none>` ).

        **Centering and scaling**: se normalizaron todos los predictores num√©ricos.

        **Correlation filter on: `ma12`**: el filtro de correlaci√≥n **elimin√≥ `ma12`** por estar **muy correlacionada** (\|œÅ\| ‚â• 0.95) con otra(s) variable(s) ‚Äît√≠picamente con `ma6`, porque son medias m√≥viles muy parecidas.

        En otras palabras: **tu dise√±o final** para el modelo qued√≥ con los predictores normalizados y **sin `ma12`** (para evitar colinealidad).

## **Especificaci√≥n del modelo y engine (parsnip)**

```{r, message=FALSE, warning=FALSE}
library(parsnip)

mod_lm <- linear_reg() %>% 
  set_engine("lm")

wf <- workflow() |> add_recipe(rec) |> add_model(mod_lm)
wf

```

-   Se define un modelo de **regresi√≥n lineal** (`linear_reg()`),

    Se indica que se va a usar el motor de R base `"lm"` (`set_engine("lm")`).\
    Esto es la parte de **parsnip**: declara **qu√© modelo quieres**, pero a√∫n no lo entrenas.

-   `workflow()` crea un contenedor donde integras **preprocesamiento + modelo**.

    `add_recipe(rec)` a√±ade la receta (`rec`) donde definiste las transformaciones de los datos.

    `add_model(mod_lm)` a√±ade el modelo de regresi√≥n lineal que acabas de definir.

-   **Preprocessor: Recipe**

    -   Indica que usaste una receta con **3 pasos**:

        -   `step_zv()`: elimina variables con **varianza cero** (sin informaci√≥n).

            `step_normalize()`: normaliza las variables (media 0, varianza 1).

            `step_corr()`: elimina predictores altamente correlacionados (evita multicolinealidad).

**Ajuste, predicci√≥n y diagn√≥stico**

```{r, message=FALSE, warning=FALSE}
#| label: fit-predict
fit_lm <- fit(wf, data = train)
preds  <- predict(fit_lm, new_data = test) |>
  bind_cols(test |> select(date, gold_next_ret))

preds |> slice_tail(n=24) |>
  gt() |> tab_header(title="Predicciones (√∫ltimas filas)") |>
  fmt_num(c(.pred, gold_next_ret), dec=6)
```

### Qu√© hace cada l√≠nea

-   `fit_lm <- fit(wf, data = train)`\
    Ajusta el **workflow** (receta + modelo `lm`) solo con el conjunto *train*.

    `predict(fit_lm, new_data = test)`\
    Genera la columna **`.pred`** (predicci√≥n del retorno del oro) sobre *test*.

    `bind_cols(test |> select(date, gold_next_ret))`\
    Anexa a las predicciones la **fecha** y el **resultado real** (`gold_next_ret`) para comparar.

    `slice_tail(n = 8)`\
    Muestra las **8 √∫ltimas observaciones** (√∫til si los datos son cronol√≥gicos).

### C√≥mo leer la tabla

-   **`.pred`**: lo que estima el modelo.

    **`gold_next_ret`**: el valor **real** observado.

    Comparando ambos puedes evaluar si el modelo **subestima** o **sobreestima** en cada fecha.

    -   Ej.: 2024-02-01 ‚Üí `.pred = -0.011772` vs real `0.065018` ‚Üí fuerte **subestimaci√≥n** (residuo ‚âà +07679.0).

```{r, message=FALSE, warning=FALSE}
#| label: fig-pred-real
#| fig-cap: "Test: Real vs Predicho"
preds |>
  ggplot(aes(gold_next_ret, .pred)) +
  geom_point(alpha=0.7) +
  geom_smooth(method="lm", se=FALSE, linewidth=0.9) +
  labs(x="Real", y="Predicho") + theme_minimal()
```

-   **Qu√© muestra**:

    -   Eje X ‚Üí valores reales de la variable dependiente (`gold_next_ret`).

        Eje Y ‚Üí valores predichos por el modelo (`.pred`).

        La l√≠nea azul es un ajuste lineal auxiliar que indica la tendencia.

    **Interpretaci√≥n**:

    Existe una **relaci√≥n positiva**, pero d√©bil: cuando el valor real aumenta, el modelo tiende a predecir valores mayores, aunque con bastante dispersi√≥n.

    -   Muchos puntos se alejan de la l√≠nea, lo que indica que el modelo no captura bien la variabilidad de los datos.

    -   Idealmente, si el modelo fuera perfecto, los puntos deber√≠an alinearse en una diagonal con pendiente = 1 (l√≠nea identidad). Aqu√≠, la nube dispersa muestra que el ajuste es limitado.

```{r, message=FALSE, warning=FALSE}
#| label: resid-time
#| fig-cap: "Residuos en Test"
preds |>
  mutate(resid = gold_next_ret - .pred) |>
  ggplot(aes(date, resid)) +
  geom_hline(yintercept=0, linetype=2, color="gray50") +
  geom_line(linewidth=0.8, color="firebrick") +
  theme_minimal() + labs(x=NULL, y="Residual")

```

-   **Qu√© muestra**:

    -   Eje X ‚Üí tiempo (fecha).

        Eje Y ‚Üí residuo = real ‚àí predicho.

    -   La l√≠nea punteada en 0 indica el ideal (residuos centrados en cero).

    -   **Interpretaci√≥n**

    Los residuos oscilan en torno a cero, pero se observan **patrones c√≠clicos** (suben y bajan en bloques).

    -   Esto sugiere que el modelo **no captura componentes temporales o estacionales** de la serie (muy t√≠pico en series financieras/temporales)

        Aunque no hay una tendencia clara de crecimiento en magnitud (no aumenta la varianza con el tiempo), s√≠ se aprecia estructura ‚Üí indicio de autocorrelaci√≥n en los errores.

-   **Conclusi√≥n general**

1.  El modelo de regresi√≥n lineal capta la direcci√≥n general (positiva) pero con **poder predictivo d√©bil**.

2.  Los residuos muestran estructura temporal, lo que indica que **no son completamente aleatorios** ‚Üí se viola el supuesto de independencia.

3.  Para datos con fechas (series temporales), ser√≠a recomendable probar modelos que incorporen dependencia temporal, como:

-   Modelos de machine learning adaptados a series temporales (XGBoost con lags, Prophet, LSTM, etc.).

```{r, message=FALSE, warning=FALSE}
#| label: engine-diagnostics
eng <- fit_lm |> extract_fit_engine()
broom::glance(eng) |>
  gt() |> tab_header(title="Resumen (engine lm)") |>
  fmt_num(c(r.squared, adj.r.squared, sigma, AIC, BIC, statistic, p.value), dec=6)

lmtest::dwtest(eng); lmtest::bptest(eng); performance::check_model(eng)

```

### 1. **Durbin‚ÄìWatson**

-   **Hip√≥tesis:**

    -   H‚ÇÄ: no hay autocorrelaci√≥n de primer orden en los residuos.

        H‚ÇÅ: existe autocorrelaci√≥n positiva.

    **Resultado:** DW = 2.1906, p-valor = 0.7778.

    **Interpretaci√≥n:** DW ‚âà 2 y p-valor alto ‚Üí no se rechaza H‚ÇÄ

### 2. **Breusch‚ÄìPagan**

-   **Hip√≥tesis:**

    H‚ÇÄ: varianza constante de los residuos (homocedasticidad).

    H‚ÇÅ: heterocedasticidad.

    **Resultado:** BP = 12.134, p-valor = 0.03299.

    **Interpretaci√≥n:** p-valor \< 0.05 ‚Üí se rechaza H‚ÇÄ.\
    **Hay evidencia de heterocedasticidad** en los residuos.

**Panel gr√°fico**

-   **Posterior Predictive Check**

    -   La densidad de los datos observados y predichos es parecida, aunque el modelo suaviza demasiado los extremos.\
        Ajuste razonable pero con p√©rdida de variabilidad en colas

-   **Linearity**

Residuos frente a valores ajustados ‚Üí no hay una curva clara, pero s√≠ dispersi√≥n irregular.\
La relaci√≥n lineal es aceptable, aunque no perfecta.

**Homogeneity of Variance**

Los residuos deber√≠an estar en una banda horizontal.

-   Aqu√≠ se observa dispersi√≥n creciente en algunos tramos.

    Refuerza lo detectado por Breusch‚ÄìPagan: **heterocedasticidad**.

**Influential Observations (Cook‚Äôs D / leverage)**

La mayor√≠a de puntos est√° dentro de las l√≠neas de influencia, pero algunos se acercan al borde.\
xisten observaciones influyentes, aunque no excesivas.

**Collinearity (VIF)**

-   Todos los predictores tienen VIF \< 5 (umbral de preocupaci√≥n).

    **No hay problema grave de multicolinealidad**.

-   **Normality of Residuals (Q-Q plot)**

La mayor√≠a de puntos sigue la diagonal, salvo en las colas.\
Los residuos son aproximadamente normales, con ligeras desviaciones en valores extremos. \## M√©tricas y validaci√≥n temporal

```{r}
#| label: metrics
yardstick::metrics(preds, truth = gold_next_ret, estimate = .pred) |>
  gt() |> tab_header(title="M√©tricas en Test") |> fmt_num(.estimate, dec=6)

```

-   **RMSE (Root Mean Squared Error) = 0.0431**\
    ‚Üí Error cuadr√°tico medio de alrededor del 4.3% en los retornos.\
    Mientras m√°s bajo, mejor.

    **MAE (Mean Absolute Error) = 0.0345**\
    ‚Üí En promedio, la predicci√≥n se equivoca en ¬±3.4% del retorno.

    **R¬≤ (rsq) = 0.1303**\
    ‚Üí El modelo explica apenas el **13% de la variabilidad** en el retorno del oro.\
    Esto es bastante bajo, indicando que la regresi√≥n lineal simple capta muy poco de la din√°mica real.

-   Conclusi√≥n: **el modelo tiene baja capacidad predictiva** en el test. Captura algo de se√±al, pero la mayor√≠a del comportamiento sigue siendo ruido.

```{r}
#| label: rolling-origin
set.seed(123)
rs <- rolling_origin(
  datos,
  initial = 60, assess = 12, skip = 6, cumulative = TRUE
)
res_cv <- fit_resamples(wf, resamples = rs, control = control_resamples(save_pred = TRUE))
collect_metrics(res_cv) |>
  gt() |> tab_header(title="CV temporal (promedios)") |> fmt_num(c(mean, std_err), dec=6)

```

-   **RMSE promedio = 0.0366 (¬±0.0021)**\
    ‚Üí En promedio, el error cuadr√°tico medio de predicci√≥n es \~3.7%.\
    ‚Üí Es un poco mejor que el RMSE en el test simple (0.0431).

    **R¬≤ promedio = 0.0479 (¬±0.0140)**\
    ‚Üí El modelo solo explica alrededor del **5% de la variabilidad** en los retornos.\
    ‚Üí Es incluso m√°s bajo que en el test simple (0.13).\
    ‚Üí Esto confirma que el modelo **no generaliza bien** a lo largo del tiempo.

    -   **Capacidad predictiva:** aunque el RMSE no es alto en t√©rminos absolutos, el R¬≤ cercano a cero muestra que la regresi√≥n lineal **apenas supera a un modelo trivial (predicci√≥n constante en la media)**.

        **Confirmaci√≥n:** lo que viste en test simple no fue casualidad: el modelo lineal **no logra capturar patrones temporales** en los retornos del oro.

    -   El modelo de regresi√≥n lineal **tiene poco poder explicativo** en series financieras de retornos

    -   Usar algoritmos de ML m√°s flexibles con rolling CV (Random Forest, XGBoost, redes neuronales).

        Para mejorar, se recomienda:

        -   Incorporar **lags (retardos)** del oro y de los predictores.

## Conclusi√≥n Final del Modelo

-   **Ajuste del modelo**

    Se especific√≥ y entren√≥ un modelo de **regresi√≥n lineal** en el framework **tidymodels**, con un flujo completo: preprocesamiento (normalizaci√≥n, eliminaci√≥n de variables redundantes), ajuste y evaluaci√≥n.

    -   El modelo permiti√≥ obtener predicciones y realizar diagn√≥sticos formales (residuos, autocorrelaci√≥n, heterocedasticidad, normalidad, influencia),

-   **Resultados en Test**

**RMSE ‚âà 0.043** y **MAE ‚âà 0.034** ‚Üí errores moderados en escala de retornos.

**R¬≤ ‚âà 0.13** ‚Üí el modelo explica apenas un 13% de la variabilidad.

**Validaci√≥n Temporal (rolling-origin)**

-   **RMSE promedio ‚âà 0.037**, estable en distintas ventanas temporales.

    **R¬≤ promedio ‚âà 0.048**, cercano a cero ‚Üí el modelo tiene poca capacidad explicativa.

    Esto confirma que los resultados en test simple no fueron casualidad: la regresi√≥n lineal **no capta patrones temporales robustos en los retornos**.

-   **Diagn√≥stico de supuestos**

-   **No autocorrelaci√≥n** significativa de los residuos (Durbin‚ÄìWatson correcto).

    **Heterocedasticidad presente** (Breusch‚ÄìPagan significativo).

    Residuos aproximadamente normales, con desv√≠os en colas.

    Sin problemas graves de multicolinealidad (VIF \< 5).

    **Interpretaci√≥n econ√≥mica y pr√°ctica**

-   El retorno del oro no puede explicarse bien solo con regresores lineales como d√≥lar, petr√≥leo, inflaci√≥n o indicadores t√©cnicos.

    Los resultados reflejan la **alta aleatoriedad y ruido en series financieras de retornos**, donde los modelos lineales b√°sicos son insuficientes.

    ```{r}
    #| label: tabla-preds-ic
    #| message: false
    #| warning: false
    library(tidyverse)
    library(gt)

    # Intento 1: pedir IC al workflow (parsnip reciente lo soporta)
    preds_ci <- tryCatch({
      predict(fit_lm, new_data = test, type = "conf_int") %>%
        bind_cols(
          predict(fit_lm, new_data = test, type = "numeric"),
          test %>% select(date, gold_next_ret)
        )
    }, error = function(e) {
      # Fallback: extraer el lm interno y hornear test con la receta
      rec_prep   <- recipes::prep(rec)
      test_baked <- recipes::bake(rec_prep, new_data = test)
      eng_lm     <- workflows::extract_fit_engine(fit_lm)  # objeto 'lm'
      ci_lm      <- as.data.frame(predict(eng_lm, newdata = test_baked, interval = "confidence"))
      names(ci_lm) <- c(".pred", ".pred_lower", ".pred_upper")
      bind_cols(test %>% select(date, gold_next_ret), ci_lm)
    })

    # Rango de fechas efectivamente predicho en TEST
    rango <- preds_ci %>% summarise(min_fecha = min(date), max_fecha = max(date))
    print(rango)

    # Tabla de los √∫ltimos 12 meses
    preds_ci %>%
      arrange(date) %>%
      slice_tail(n = 12) %>%
      select(date, gold_next_ret, .pred, .pred_lower, .pred_upper) %>%
      gt() %>%
      tab_header(title = "LM m√∫ltiple: Real vs Predicho (IC 95%) ‚Äî √∫ltimos 12 meses") %>%
      fmt_number(columns = c(gold_next_ret, .pred, .pred_lower, .pred_upper),
                 decimals = 6, dec_mark = ",", sep_mark = ".")

    ```

```{r}
#| label: graf-preds-ic
#| fig-cap: "Regresi√≥n lineal m√∫ltiple: Real vs Predicho con IC 95%"
#| message: false
#| warning: false
library(ggplot2)

preds_ci %>%
  arrange(date) %>%
  ggplot(aes(date)) +
  geom_line(aes(y = gold_next_ret), linewidth = 0.7, alpha = 0.9) +
  geom_ribbon(aes(ymin = .pred_lower, ymax = .pred_upper), alpha = 0.20) +
  geom_line(aes(y = .pred), linewidth = 0.9, color = "blue") +
  labs(
    title   = "Regresi√≥n lineal m√∫ltiple: Real vs Predicho con IC 95%",
    x = NULL, y = "Retorno del oro (t+1)",
    caption = "L√≠nea negra: real | L√≠nea azul: predicho | Banda: IC 95% (media condicional)"
  ) +
  theme_minimal()

```

# Unidad 4. Regresi√≥n Log√≠stica

En an√°lisis econom√©trico, cuando la variable dependiente es **binaria** (toma valores 0 o 1), como por ejemplo:

-   Trabaja (1) o no trabaja (0)

-   Est√° enfermo (1) o no est√° enfermo (0),

-   Vota por un candidato (1) o no (0),

El uso de un modelo de regresi√≥n lineal tradicional no es adecuado. El **modelo logit** se propone como una soluci√≥n, garantizando que las probabilidades predichas est√©n siempre en el rango **\[0,1\]** gracias a la funci√≥n log√≠stica.

1.  **Probabilidad en el modelo logit**

    $$
    P(Y=1 \mid X) \;=\; \frac{e^{\beta_0 + \beta_1 X_1 + \cdots + \beta_k X_k}}{1 + e^{\beta_0 + \beta_1 X_1 + \cdots + \beta_k X_k}}
    $$

2.  **Forma de raz√≥n de probabilidades (odds)**; definimos la raz√≥n de probabilidades u odds como:

$$
\text{odds} \;=\; \frac{P(Y=1 \mid X)}{1 - P(Y=1 \mid X)}
$$

1.  **Linealizaci√≥n mediante el logit**

    Al aplicar logaritmo a los odds, obtenemos la funcion logit, que es lineal en los par√°metros

$$
\text{logit}(P) \;=\; \ln\left(\frac{P(Y=1 \mid X)}{1 - P(Y=1 \mid X)}\right) 
= \beta_0 + \beta_1 X_1 + \cdots + \beta_k X_k
$$

1.  **Interpretaci√≥n de los coeficientes**

    Un cambio unitario en $X_i$ altera las odds en un factor multiplicativo:

    $$
    \Delta \text{odds} \;=\; e^{\beta_i}
    $$

**Ejemplo pr√°ctico**

Queremos modelar la probabilidad de que el **precio del oro aumente en un d√≠a** ( $Y$=1) o **no aumente** ($Y$=0), en funci√≥n de variables financieras:

-   **Variaci√≥n del d√≥lar**: rendimiento diario del d√≥lar

-   **Tasa de inter√©s** : nivel de la tasa de inter√©s de referencia.

    Variable dependiente (Binaria)

$$
Y = 
\begin{cases} 
1 & \text{si el precio del oro sube ese d√≠a} \\ 
0 & \text{si baja o se mantiene} 
\end{cases}
$$

2.  **¬øC√≥mo queda el modelo logit?**

$$
P(Y=1 \mid X) \;=\; 
\frac{e^{\beta_0 + \beta_1 \cdot dollar\_ret + \beta_2 \cdot rate}}
{1 + e^{\beta_0 + \beta_1 \cdot dollar\_ret + \beta_2 \cdot rate}}
$$

3.  **Resultados simulados:**

    Supongamos que la estimaci√≥n nos da:

    -   $B_0$ =-0.5
    -   $B_1$ = -2.0 (rendimiento del d√≥lar)
    -   $B_2$ = -0.3 (tasa de inter√©s)

    **Modelo estimado**

$$
\hat{P}(Y=1 \mid X) \;=\; 
\frac{e^{-0.5 - 2.0 \cdot dollar\_ret - 0.3 \cdot rate}}
{1 + e^{-0.5 - 2.0 \cdot dollar\_ret - 0.3 \cdot rate}}
$$

4.  **Interpretaci√≥n de los coeficientes**

    **Coeficiente del Dolar**

    Si el d√≥lar sube un punto porcentual, las *odds* de que el oro suba **se reducen en un factor**

$$
e^{-2.0} \;\approx\; 0.14
$$

En t√©rminos pr√°cticos: cuando el d√≥lar se fortalece, el oro casi siempre baja (relaci√≥n inversa cl√°sica).

**Coeficiente de la tasa de inter√©s**

Un incremento de un punto en la tasa de inter√©s reduce las *odds* de que el oro suba en un factor

$$
e^{-0.3} \;\approx\; 0.74
$$

Es decir, tasas m√°s altas desincentivan la inversi√≥n en oro (activo de refugio sin rendimiento).

**Supongamos:**

-   $dollar_ret=‚àí0.01$ el d√≥lar cae 1%

-   $rate=2$%

-   **Sustituimos**

$$
z = -0.5 - 2.0(-0.01) - 0.3(2) 
= -0.5 + 0.02 - 0.6 
= -1.08
$$

$$
\hat{P}(Y=1) \;=\; 
\frac{e^{-1.08}}{1 + e^{-1.08}} 
\;\approx\; 0.25
$$

La probabilidad de que el oro suba bajo esas condiciones es **25%**.

```{r, echo=FALSE, message=FALSE, warning=FALSE}

#| message: false
suppressPackageStartupMessages({
  library(tidyverse)
  library(tidymodels)  # rsample, recipes, parsnip, workflows, yardstick, tune, dials
  library(themis)      # pasos de balanceo (SMOTE, ROSE, etc.)
  library(gt)
  library(scales)
})

# Asegura que la clase objetivo sea factor con niveles (DOWN, UP)
d <- d |>
  mutate(up_next = factor(up_next, levels = c("DOWN","UP"))) |>
  drop_na(up_next, dollar_ret, wti_ret, infl_yoy, ma6, ma12, rsi14)

# Baseline de clase mayoritaria (para comparar)
tabla_clase <- d |>
  count(up_next, name = "n") |>
  mutate(prop = n/sum(n))

gt(tabla_clase) |>
  tab_header(title = "Distribuci√≥n de clases (objetivo: up_next)") |>
  fmt_number(columns = prop, decimals = 3, dec_mark = ",", sep_mark = ".")

```

# **Partici√≥n temporal 80/20**

```{r}

set.seed(123)
datos_cls <- d |>
  select(date, up_next, dollar_ret, wti_ret, infl_yoy, ma6, ma12, rsi14) |>
  arrange(date)

split_cls <- initial_time_split(datos_cls, prop = 0.80)
train_cls  <- training(split_cls)
test_cls   <- testing(split_cls)

tibble(
  n_train = nrow(train_cls), n_test = nrow(test_cls),
  min_train = min(train_cls$date), max_train = max(train_cls$date),
  min_test  = min(test_cls$date),  max_test  = max(test_cls$date)
) |>
  gt() |> tab_header(title = "Partici√≥n temporal (clasificaci√≥n)")
```

## Feature Engineering (recipes)

```{r}
rec_cls <- recipe(
  up_next ~ dollar_ret + wti_ret + infl_yoy + ma6 + ma12 + rsi14,
  data = train_cls
) |>
  step_zv(all_predictors()) |>               # quita columnas constantes
  step_normalize(all_numeric_predictors()) |> # centra/escala num√©ricos
  step_corr(all_numeric_predictors(), threshold = 0.95) # colinealidad severa
rec_cls
# (Opcional) Si ves desbalance fuerte, puedes balancear SOLO en train:
# rec_cls <- rec_cls |> step_smote(up_next, over_ratio = 1) 
# -> requiere library(themis)
```

**Por qu√©:** normalizamos escalas; reducimos colinealidad (`ma6` vs `ma12`); opcionalmente balanceamos (SMOTE) si la clase UP o DOWN es muy minoritaria.

## **Especificaci√≥n del modelo**

```{r}
mod_log <- logistic_reg() |>
  set_engine("glm") |>
  set_mode("classification")

summary(mod_log)
```

**Por qu√©:** `glm` log√≠stica es interpretable y un buen baseline; luego puedes pasar a `glmnet` con penalizaci√≥n si quieres.

## Workflow

```{r}
wf_cls <- workflow() |>
  add_recipe(rec_cls) |>
  add_model(mod_log)

wf_cls

```

**Por qu√©:** asegura que el preprocesamiento (receta) se aplique **dentro** del pipeline (sin data leakage) antes de entrenar/predicir.

## **Ajuste (fit) y predicci√≥n en test**

```{r}

fit_log <- fit(wf_cls, data = train_cls)

# Probabilidades y clases (umbral 0.5 por defecto)
pred_cls <- predict(fit_log, new_data = test_cls, type = "prob") |>
  bind_cols(predict(fit_log, new_data = test_cls, type = "class")) |>
  bind_cols(test_cls |> select(date, up_next))

pred_cls |> head() |> gt() |> tab_header(title = "Predicciones (muestra)")
```

-   `type = "prob"` devuelve `(.pred_DOWN, .pred_UP)`

    `type = "class"` usa umbral 0.5 para asignar clase

-   Qu√© significan las columnas

<!-- -->

-   **`.pred_DOWN` y `.pred_UP`**\
    Son las **probabilidades estimadas** de que la variable respuesta tome cada clase.

    -   Ejemplo: `0.829 ‚Üí DOWN`, `0.171 ‚Üí UP`.

    **`.pred_class`**\
    Es la **clase predicha** por el modelo. Se asigna seg√∫n la probabilidad mayor (umbral 0.5 por defecto).

    -   Si `pred_DOWN > 0.5`, la clase es *DOWN*.

        Si `pred_UP > 0.5`, la clase es *UP*.

    **`date`**\
    El per√≠odo de la observaci√≥n en el set de prueba.

    **`up_next`**\
    La **clase real observada** (lo que efectivamente pas√≥ en la variable dependiente).

## üîé Interpretaci√≥n de la muestra

1.  **Primera fila (2021-07-01)**

    -   Modelo: 82.9% probabilidad de *DOWN*.

        Predicci√≥n: *DOWN*.

        Realidad: *DOWN*.\
        ‚Üí ‚úÖ Acierto.

    2.  **Segunda fila (2021-09-01)**

        Prob. *DOWN* 83.1% vs *UP* 16.9%.

        Predicci√≥n: *DOWN*.

        Realidad: *DOWN*.\
        ‚Üí ‚úÖ Acierto.

    3.  **Tercera fila (2021-10-01)**

    4.  Prob. *DOWN* 87.4% vs *UP* 12.6%.

        Predicci√≥n: *DOWN*.

        Realidad: *UP*.\
        ‚Üí ‚ùå Error: el modelo estaba muy seguro pero se equivoc√≥.

    **Cuarta fila (2021-11-01)**

    -   Prob. *DOWN* 87.5%.

        Predicci√≥n: *DOWN*

        Realidad: *DOWN*.\
        ‚Üí ‚úÖ Acierto

    **Quinta fila (2021-12-01)**

    -   Prob. *DOWN* 89.3%.

        Predicci√≥n: *DOWN*.

        Realidad: *DOWN*.\
        ‚Üí ‚úÖ Acierto.

    -   **Sexta fila (2022-01-01)**

        Prob. *DOWN* 89.3%.

        Predicci√≥n: *DOWN*.

        Realidad: *UP*.\
        ‚Üí ‚ùå Error.

## Evaluaci√≥n de la clasificaci√≥n

### M√©tricas b√°sicas

```{r}
# Accuracy, Kappa, etc.
metrics_overall <- yardstick::metrics(pred_cls, truth = up_next, estimate = .pred_class)
gt(metrics_overall) |> tab_header(title = "M√©tricas (umbral 0.5)")

```

## Resultados mostrados

-   **Accuracy (Exactitud): 0.467**

    -   El modelo acierta en **‚âà47% de los casos**.

        Esto es **peor que lanzar una moneda al aire (50%)**, lo cual indica que el modelo no est√° aprendiendo un patr√≥n √∫til con el umbral de 0.5.

    **Kappa (Cohen‚Äôs Kappa): 0.000**

    -   Kappa mide el acuerdo entre lo predicho y lo real, corrigiendo por el azar.

        Un valor **cercano a 0** significa que el modelo **no predice mejor que el azar**.

        Valores aceptables suelen estar sobre 0.2 (d√©bil), 0.4 (moderado), 0.6+ (fuerte).

## üîé Interpretaci√≥n

1.  **Sesgo hacia una clase**\
    El modelo probablemente **predice la mayor√≠a de las veces la clase DOWN**, lo que hace que falle cuando la clase real es UP.\
    Esto puede deberse a un **desbalance de clases** en los datos de entrenamiento.

    **Umbral fijo (0.5)**\
    Con un umbral de decisi√≥n de 0.5, el modelo puede estar siendo demasiado r√≠gido. Quiz√°s ajustando el umbral se mejore el equilibrio entre **sensibilidad (recall)** y **precisi√≥n (precision)**.

    **Valor pr√°ctico**\
    Tal como est√°, el modelo **no es confiable** para tomar decisiones, porque no supera el azar. Necesita:

    -   Revisi√≥n de **balance de clases** (ej. *downsample*, *upsample*, SMOTE).

        Revisi√≥n de **features** (quiz√°s faltan variables explicativas relevantes).

        Ajuste del **umbral** para clasificar.

## Matriz de confusi√≥n + sensibilidad /especificidad

```{r}
cm <- conf_mat(pred_cls, truth = up_next, estimate = .pred_class)
cm

# Sensibilidad (TPR) y especificidad (TNR)
sens <- sens(pred_cls, truth = up_next, estimate = .pred_class, event_level = "second")  # 'UP' es el segundo nivel
spec <- spec(pred_cls, truth = up_next, estimate = .pred_class, event_level = "second")

bind_rows(sens, spec) |>
  gt() |> tab_header(title = "Sensibilidad y Especificidad (umbral 0.5)")

```

-   **14 aciertos en DOWN** ‚Üí el modelo predijo *DOWN* cuando realmente fue *DOWN*.

    **16 errores en UP** ‚Üí el modelo siempre predijo *DOWN*, incluso cuando la realidad era *UP*.

    **0 aciertos en UP** ‚Üí el modelo nunca predijo *UP*.

    -   **Sensibilidad (Recall para UP):**

        -   La sensibilidad mide la capacidad de detectar correctamente los positivos (*UP*).

            Aqu√≠ es **0%**, porque nunca se predijo *UP* cuando realmente ocurri√≥.

            ‚ö†Ô∏è El modelo **falla totalmente en detectar la clase UP**.

        -   **Especificidad (Recall para DOWN): 1**

        -   La especificidad mide la capacidad de detectar correctamente los negativos (*DOWN*).

            Aqu√≠ es **100%**, porque **todo lo que fue DOWN se predijo como DOWN**.

            Pero ojo: esto se logra porque el modelo **siempre predice DOWN**, lo cual sesga completamente los resultados.

    -   El modelo est√° **totalmente sesgado hacia la clase DOWN**.

        Esto es t√≠pico en un problema de **desbalance de clases**: si hay m√°s casos de *DOWN* en los datos de entrenamiento, el modelo aprende a "jugar seguro" prediciendo siempre esa clase.

        Por eso:

        -   Accuracy global bajo (‚âà47%)

            Kappa = 0 (no mejor que el azar).

            Sensibilidad = 0 (incapaz de detectar *UP*).

            Especificidad = 1 (detecta bien *DOWN*, pero por sesgo, no por aprendizaje real).

```{r}
table(train_cls$up_next) / nrow(train_cls)

```

### **Curva ROC/AUC y Pr AUC**

```{r}
roc_auc(pred_cls, truth = up_next, .pred_UP, event_level = "second")

roc_df <- roc_curve(pred_cls, truth = up_next, .pred_UP, event_level = "second")
autoplot(roc_df) + ggtitle("ROC Curve (Logistic glm)")

pr_df <- pr_curve(pred_cls, truth = up_next, .pred_UP, event_level = "second")
autoplot(pr_df) + ggtitle("Precision‚ÄìRecall Curve")

```

**Por qu√©:** ROC/AUC resumen discriminaci√≥n global; PR-AUC √∫til cuando la clase positiva es rara.

## Resultados clave

**ROC AUC = 0.585**

-   El √°rea bajo la curva ROC mide la capacidad del modelo para discriminar entre *UP* y *DOWN*.

    -   Un valor de **0.5 indica azar puro**, y **1.0 indica discriminaci√≥n perfecta**.

    -   Con **0.585**, tu modelo discrimina apenas un poco mejor que el azar, lo cual es **d√©bil desempe√±o**.

    **Curva ROC**

    -   La curva est√° muy cercana a la diagonal (l√≠nea punteada = azar).

    -   Esto confirma que el poder predictivo es bajo: el modelo no logra separar bien entre positivos (UP) y negativos (DOWN).

    **Curva Precisi√≥n‚ÄìRecall**

    -   La precisi√≥n cae r√°pido a medida que aumenta el recall.

        Esto muestra que cuando intentas capturar m√°s casos *UP* (mayor recall), lo haces a costa de perder precisi√≥n (muchos falsos positivos).

        Una curva que se mantiene alta y hacia la esquina superior derecha indicar√≠a buen desempe√±o, pero aqu√≠ est√° bastante dispersa.

### Afinar umbral

```{r}
library(tidymodels)

# 1) Curva PR (precision & recall por umbral)
pr_tbl <- pr_curve(pred_cls,
                   truth = up_next, 
                   .pred_UP,                 # sin "estimate ="
                   event_level = "second")   # 'UP' es la clase positiva

# 2) Calcular F1 por umbral y elegir el mejor
best_row <- pr_tbl %>%
  filter(!is.na(.threshold)) %>%               # descarta el punto inicial (NA)
  mutate(F1 = 2 * precision * recall / (precision + recall)) %>%
  arrange(desc(F1)) %>%
  slice(1)

best_row
thr <- best_row$.threshold

# 3) Re-clasificar con el umbral √≥ptimo y evaluar
pred_thr <- pred_cls %>%
  mutate(.pred_class_thr = factor(if_else(.pred_UP >= thr, "UP", "DOWN"),
                                  levels = c("DOWN","UP")))

metrics(pred_thr, truth = up_next, estimate = .pred_class_thr) %>%
  gt() %>%
  tab_header(title = paste0("M√©tricas con umbral √≥ptimo (F1) = ", round(thr, 3)))


```

## Resultados con umbral √≥ptimo (F1)

-   **Umbral = 0.101**\
    ‚Üí Esto significa que cualquier probabilidad de *UP* ‚â• 0.101 se clasifica como *UP*.\
    ‚Üí Es un umbral **mucho m√°s bajo que 0.5**, lo que permite al modelo detectar casos *UP* que antes ignoraba.

    **Recall (sensibilidad para UP) = 0.938**\
    ‚Üí El modelo ahora **detecta el 93.7% de los casos UP**.\
    ‚Üí Excelente mejora (antes era 0%).

    **Precision (precisi√≥n para UP) = 0.60**\
    ‚Üí De todas las predicciones *UP*, el 60% fueron correctas.\
    ‚Üí Aceptable, considerando que antes era inexistente.

    **F1 = 0.731**\
    ‚Üí El F1 combina recall y precision.\
    ‚Üí Mejor√≥ sustancialmente (antes ‚âà0).

    **Accuracy = 0.633**\
    ‚Üí El modelo acierta en el 63.3% de los casos totales.\
    ‚Üí Mejor que el azar (50%) y tambi√©n mejor que con umbral 0.5 (46.7%).

    **Kappa = 0.233**\
    ‚Üí A√∫n bajo, pero mejor que 0.\
    ‚Üí Indica un acuerdo d√©bil, aunque ya superior al azar.

## üîé Interpretaci√≥n

1.  El ajuste de umbral **corrige el sesgo**: ahora el modelo s√≠ detecta *UP*.

2.  El costo: aumenta la probabilidad de falsos positivos, pero se logra un balance mejor entre sensibilidad y precisi√≥n.

3.  Este cambio **mejora notablemente la utilidad pr√°ctica del modelo**, especialmente si es cr√≠tico no perder casos *UP*.

4.  Sin embargo, la **AUC (‚âà0.58)** muestra que la capacidad discriminativa del modelo sigue siendo limitada.

## üöÄ Recomendaciones

-   **Mantener este an√°lisis como evidencia** de que el umbral fijo 0.5 no era adecuado.

    Explorar t√©cnicas adicionales para mejorar la discriminaci√≥n:

    -   Balanceo de clases en el entrenamiento (SMOTE, undersampling, oversampling).

    -   Modelos no lineales (√°rboles, random forest, XGBoost).

    -   Inclusi√≥n de m√°s variables predictoras relevantes.

    Reportar tanto las m√©tricas con **umbral est√°ndar (0.5)** como con **umbral optimizado (‚âà0.101)** para mostrar la ganancia.

üìå Resumen:\
Con el umbral optimizado (0.101), el modelo pas√≥ de **‚Äúno detectar nunca UP‚Äù** a **capturar casi todos los UP (93.7% de recall)**, con un nivel razonable de precisi√≥n (60%) y una mejora clara en exactitud y F1.

### **Interpretaci√≥n del Modelo**

```{r}
# Extraer el glm "interno" y ver coeficientes
eng_log <- fit_log |> extract_fit_engine()   # objeto glm
summary(eng_log)

# Odds Ratios (e^beta) y CIs
coefs <- broom::tidy(eng_log, conf.int = TRUE, exponentiate = TRUE)
gt(coefs) |>
  tab_header(title = "Odds Ratios (exp(beta)) ‚Äì glm") |>
  fmt_number(c(estimate, conf.low, conf.high), decimals = 3, dec_mark = ",", sep_mark = ".")

```

## Resumen del modelo

Se ajust√≥ un **GLM binomial (logit)** para explicar la probabilidad de que la variable dependiente yyy tome valor 1, en funci√≥n de:

-   **dollar_ret** (retorno del d√≥lar)

-   **wti_ret** (retorno del petr√≥leo WTI)

-   **infl_yoy** (inflaci√≥n interanual)

-   **ma6** (media m√≥vil a 6 periodos)

-   **rsi14** (indicador t√©cnico RSI 14 d√≠as.

## Coeficientes (log-odds)

En el primer cuadro (`summary(eng_log)`):

-   Los coeficientes representan cambios en los **log-odds** de que $Y$=1.

-   El signo indica la direcci√≥n del efecto:

    -   **Negativo** ‚Üí reduce la probabilidad de √©xito.

    -   **Positivo** ‚Üí aumenta la probabilidad de √©xito.

    La **columna Pr(\>\|z\|)** indica si el efecto es estad√≠sticamente significativo.

-   Resultados principales:

    **Intercepto**: 0.080 (p=0.682). No significativo.

    **dollar_ret**: -0.156 (p=0.519). No significativo.

    **wti_ret**: -0.040 (p=0.861). No significativo.

    **infl_yoy**: -0.389 (p=0.102). Cercano a significancia, indica que mayor inflaci√≥n podr√≠a reducir la probabilidad de √©xito.

    **ma6**: -0.306 (p=0.140). No significativo, pero con tendencia negativa.

    **rsi14**: 0.623 (p=0.006). **Significativo al 1%**, fuerte predictor positivo.

## Odds Ratios (exp(beta))

En la tabla de **odds ratios** (segunda imagen):

-   **Interpretaci√≥n**: valores \>1 indican que un aumento en la variable **incrementa la probabilidad de √©xito**; \<1 indican lo contrario.

-   Incluyen intervalos de confianza al 95%.

-   Resultados principales:

    **dollar_ret (0.855, IC 0.521‚Äì1.369)** ‚Üí efecto negativo, pero no significativo.

    **wti_ret (0.961, IC 0.610‚Äì1.552)** ‚Üí pr√°cticamente sin efecto, no significativo.

    **infl_yoy (0.678, IC 0.413‚Äì1.062)** ‚Üí reduce la probabilidad (odds m√°s bajos), casi significativo.

    **ma6 (0.737, IC 0.485‚Äì1.099)** ‚Üí reduce la probabilidad, aunque no significativo.

    **rsi14 (1.865, IC 1.207‚Äì2.973)** ‚Üí **efecto positivo y significativo**: cada aumento de una unidad en RSI multiplica por 1.86 las odds de que el evento ocurra.

## Diagn√≥stico del modelo

-   **Deviance nula**: 163.45

-   **Deviance residual**: 148.93\
    ‚Üí El modelo reduce la devianza, pero no de forma dr√°stica.

-   **AIC = 160.93** ‚Üí m√©trica de ajuste y comparaci√≥n entre modelos (menor es mejor).

-   **Iteraciones de Fisher: 4** ‚Üí convergencia r√°pida, modelo estable.

## Conclusiones

1.  El √∫nico predictor robusto es **rsi14**, que aumenta significativamente la probabilidad de √©xito en el modelo.

2.  **Inflaci√≥n (infl_yoy)** muestra un efecto negativo que merece atenci√≥n, aunque no alcanza significancia al 5% (s√≠ cercana al 10%).

3.  **Retornos del d√≥lar y del WTI** no parecen aportar informaci√≥n relevante en este caso.

4.  El modelo en general tiene un ajuste moderado (devianza reducida, AIC \~161). Puede mejorarse con:

    -   Transformaciones de variables.

    -   Inclusi√≥n de nuevas covariables (ej. tasas de inter√©s reales, volatilidad impl√≠cita, indicadores t√©cnicos adicionales).

    -   Modelos no lineales o interacciones.

üìå **Interpretaci√≥n pr√°ctica**:\
El **RSI de 14 d√≠as** es el mejor indicador para explicar la probabilidad de cambio en el oro en este modelo logit. Un aumento en RSI se traduce en casi **el doble de probabilidades** de que el evento ocurra, manteniendo las dem√°s variables constantes.

# Links de inter√©s

-   [Quarto](https://quarto.org/)
