---
title: "An√°lisis del Precio del Oro"
subtitle: "Direcci√≥n de Comercializaci√≥n de Oro ‚Äì BCE"
author: "Econ. William Ramos"
date: "`r Sys.Date()`"  
format:
  html:
    toc: true
    toc-depth: 3
    code-fold: true
    number-sections: true
    output-file: "index"
  docx: default
  pdf:
    toc: true
    number-sections: true
    df-print: kable
bibliography: referencias.bib
lang: es
params:
  fecha_corte: "2024-12-31"
---

------------------------------------------------------------------------

# Prueba

Prueba de Quarto del Banco Central del Ecuador @ghule2022gold

1.  prueba 1

2.  prueba 2

3.  prueba 3

4.  [link](https://www.bce.fin.ec/estadisticas-economicas/)

```{r, echo=FALSE}
1 + 1
```

![](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRVeaZg1T6yBJG9Rl4P8MCkpv2QYV6pALqItQ&s){fig-align="center" width="150"}

```{r}
#| label: setup
#| message: false
#| warning: false

library(tidyverse)
library(gt)
library(quantmod)
library(tidyquant)
library(TTR)
library(zoo)
library(lubridate)

# Valor por defecto de params si alguien ejecuta sin YAML/CLI
if (!exists("params") || is.null(params$fecha_corte)) {
  params <- list(fecha_corte = "2024-12-31")
}

# Rutas candidatas (si este .qmd vive en reports/)
candidatas <- c("data/gold_dataset_monthly.rds",
                "../data/gold_dataset_monthly.rds",
                "../../data/gold_dataset_monthly.rds")
ruta <- candidatas[file.exists(candidatas)][1]
if (is.na(ruta)) stop("No se encontr√≥ gold_dataset_monthly.rds en data/, ../data/ o ../../data/")

d <- readr::read_rds(ruta)

# Aplicar par√°metro de fecha
fecha_corte <- as.Date(params$fecha_corte)
d <- d |> filter(date <= fecha_corte)

# Helper de formato
fmt_usd <- function(tbl, cols) {
  tbl |> fmt_currency(columns = {{ cols }}, currency = "USD")
}

# Helpers de formato (usa sep_mark en lugar de thousands_sep)
fmt_num <- function(tbl, columns, dec = 2) {
  gt::fmt_number(
    data     = tbl,
    columns  = {{ columns }},
    decimals = dec,
    dec_mark = ",",
    sep_mark = "."
  )
}

fmt_usd <- function(tbl, columns, dec = 2) {
  gt::fmt_currency(
    data     = tbl,
    columns  = {{ columns }},
    currency = "USD",
    decimals = dec,
    dec_mark = ",",
    sep_mark = "."
  )
}
```

```{r, echo=FALSE}
d |> select(date,GOLD) %>% 
  tail(12) %>% 
  gt() %>% 
  tab_header(title = "Oro: √∫ltimos 12 meses") %>% 
  fmt_usd(columns = GOLD)
```

# Gr√°fico

```{r}
d %>% 
  ggplot(aes(date,GOLD))+
  geom_line(linewidth=0.8)+
  labs(x=NULL, y= "USD/oz", title = "Evoluci√≥n mensual del precio del oro (USD)",
  subtitle= "2006-presente",
    caption="Fuente: Yahoo Finance")+
  theme_minimal()+
  theme(
    plot.title = element_text(hjust = 0.5, size = 14, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 12, face = "italic"),
    plot.caption = element_text(hjust = 0.5, size = 9)
  )
```

**Tabla**

```{r}
d |> select(date,GOLD) %>% 
  tail(12) %>% 
  gt() %>% 
    cols_label(
      date="Fecha",
      GOLD="Precio Oro (USD)/oz"
    ) %>% 
  tab_header(title = "Oro: √∫ltimos 12 meses") %>% 
  fmt_usd(columns = GOLD) %>% 
  tab_source_note(
    source_note = "Fuente:FED"
  )
```

# **UNIDAD 2. INTRODUCCI√ìN A MACHINE LEARNING: REGRESI√ìN LINEAL**

![](images/Machine%20Learning_ML.png){fig-align="center" width="300"}

## Machine Learning

**¬øEn donde podemos aplicar Machine Learning (ML)?**

![](images/clipboard-194840170.png)

# UNIDAD 3. Creaci√≥n de un flujo de trabajo de Machine Learning (ML)

## Introducci√≥n a la regresi√≥n lineal en R-lm

La regresi√≥n lineal es un modelo estad√≠stico y de machine learning supervisado que se utiliza para explicar y predecir una variable dependiente (tambi√©n llamada variable respuesta o ***Y***) a partir de una o varias variables independientes (tambi√©n llamadas regresores, predictores o ***X***).

La idea central es ajustar una l√≠nea recta (o hiperplano en dimensiones mayores) que relacione los valores de ***X*** con los de ***Y***, minimizando la diferencia entre los valores observados y los predichos.

**Forma matem√°tica**

Para una **regresi√≥n lineal simple** (con una sola variable (X)):

$Y_i = \beta_0 + \beta_1 X_i + \varepsilon_i$

-   $Y_i$: Variable dependiente (lo que queremos explicar).\
-   $X_i$: Variable independiente (el predictor).\
-   $\beta_0$: Intercepto (valor de $Y$ cuando $X=0$).\
-   $\beta_1$: Pendiente (cambio promedio en $Y$ por cada unidad adicional de $X$).\
-   $\varepsilon_i$: t√©rmino de error (factores no observados).

------------------------------------------------------------------------

En la **regresi√≥n m√∫ltiple** (con varios predictores):

$Y_i = \beta_0 + \beta_1 X_{1i} + \beta_2 X_{2i} + \dots + \beta_k X_{ki} + \varepsilon_i$

**¬øC√≥mo se estima?**

Se utiliza el m√©todo de M√≠nimos Cuadrados Ordinarios (MCO / OLS, por sus siglas en ingl√©s), que busca los valores de los coeficiente que minimizan la suma de los errores al cuadrado:

$\min_{\beta} \sum_{i=1}^{n} (Y_i - \hat{Y}_i)^2$

**Interpretaci√≥n**

-   El modelo explica la relaci√≥n promedio lineal entre $Y$ y las variables $X$.

-   Los coeficientes \$\\beta\$ representan el efecto marginal de cada variable independiente sobre $Y$,manteniendo las dem√°s constante.

-   El $R^2$ mide el porcentaje de la variabilidad de $Y$ explicado por el modelo.

    **Ejemplo intuitivo**

    Si $Y$= **ingreso mensual** y $X$ **a√±os de educaci√≥n**

    $Ingreso$ = $\beta_0$+$\beta_1$x $Educaci√≥n$+$\varepsilon_i$

-   $\beta_0$: Ingreso esperado si la educaci√≥n = $0$

-   $\beta_1$: Cuanto aumenta (en promedio) el ingreso por cada a√±o adicional de educaci√≥n.

**En Resumen**

-   Un modelo estad√≠stico y predictivo.

-   Busca una relaci√≥n lineal entre variables

-   Se estima normalmente con m√≠nimos cuadrados.

-   Es una de las herramientas m√°s usadas en estad√≠stica, econometr√≠a y machine learning.

**¬°Vamos a la practica!**

**Observamos la gr√°fica del oro**

```{r}
plot(d$date, d$GOLD, 
     type = "l",          # "l" = line
     col = "blue", 
     lwd = 2,             # grosor de la l√≠nea
     xlab = "Fecha", 
     ylab = "Valor Oro en niveles", 
     main = "Evoluci√≥n del oro en niveles")
```

**Observamos la gr√°fica del d√≥lar**

```{r}
plot(d$date, d$DOLLAR, 
     type = "l",          # "l" = line
     col = "blue", 
     lwd = 2,             # grosor de la l√≠nea
     xlab = "Fecha", 
     ylab = "Dolar en niveles", 
     main = "Evoluci√≥n del d√≥lar en niveles")
```

**Retornos en gr√°ficos: Oro**

```{r}
plot(d$date, d$gold_ret, 
     type = "l",          # "l" = line
     col = "blue", 
     lwd = 2,             # grosor de la l√≠nea
     xlab = "Fecha", 
     ylab = "Retorno del oro", 
     main = "Evoluci√≥n del retorno del oro")
```

**Retornos en gr√°ficos: Dolar**

```{r}
plot(d$date, d$dollar_ret, 
     type = "l",          # "l" = line
     col = "blue", 
     lwd = 2,             # grosor de la l√≠nea
     xlab = "Fecha", 
     ylab = "Retorno del d√≥lar", 
     main = "Evoluci√≥n del retorno del d√≥lar")
```

```{r}
s1 <- d |>
  select(date, gold_ret, dollar_ret) |>
  drop_na()
print(s1)
```

```{r}
regresion <- lm(gold_ret ~ dollar_ret, data = s1)
summary(regresion)
```

**Interpretemos**

$$
gold\_ret_{t} = 0.006652 - 1.0913 \cdot dollar\_ret_{t} + \varepsilon_{t}
$$

**Coeficientes**

-   Intercepto: $(0.006652,\; p=0.019)$

-   Cuando el retorno del d√≥lar es cero, el retorno promedio del oro es aproximadamente $0.66\%$.\
    Es significativo al $5\%$ ($p < 0.05$).

-   Pediente: $(-1.0913,\; p < 0.001)$

-   Por cada incremento de $1$ unidad en el retorno del d√≥lar, el retorno del oro disminuye en promedio $1.09$ unidades.\
    Es altamente significativo ($p \approx 0.000000425$).\
    El signo negativo confirma la teor√≠a: la apreciaci√≥n del d√≥lar tiende a reducir el precio del oro.

**Coeficientes**

**Intercepto** $(0.006652,\; p=0.019)$

Cuando el retorno del d√≥lar es cero:

$$
\hat{Y} = 0.006652
$$

El retorno promedio del oro es ‚âà $0.66\%$.\
Es significativo al $5\%$ ($p < 0.05$).

------------------------------------------------------------------------

**Pendiente** $(-1.0913,\; p < 0.001)$

Por cada incremento de $1$ unidad en el retorno del d√≥lar:

$$
\Delta gold\_ret = -1.0913 \cdot \Delta dollar\_ret
$$

El retorno del oro disminuye en promedio $1.09$ unidades.\
Es altamente significativo ($p \approx 0.000000425$).\
El signo negativo confirma la teor√≠a: la apreciaci√≥n del d√≥lar tiende a reducir el precio del oro.

------------------------------------------------------------------------

üîπ **Bondad de ajuste**

$$
R^2 = 0.1612 \quad (16.1\%)
$$

El modelo explica solo un $16\%$ de la variaci√≥n en el retorno del oro.\
Esto es com√∫n en series financieras: el oro depende de m√∫ltiples factores, no solo del d√≥lar.

$$
R^2_{ajustado} = 0.155
$$

Confirma que la complejidad no a√±ade mucha p√©rdida.

Error est√°ndar residual:

$$
\sigma_{\hat{\varepsilon}} = 0.03408
$$

En promedio, los residuos (errores) son de $3.4$ puntos porcentuales.

------------------------------------------------------------------------

üîπ **Pruebas de significancia global**

$$
F = 28.06, \quad p < 0.001
$$

El modelo en su conjunto es estad√≠sticamente significativo.\
Al menos un coeficiente (aqu√≠ $\beta_1$) difiere de cero.

------------------------------------------------------------------------

üîπ Resumen interpretativo

-   **Direcci√≥n:** relaci√≥n negativa clara entre d√≥lar y oro.\
-   **Magnitud:** movimientos del d√≥lar tienen un efecto importante en el oro.\
-   **Significancia:** el efecto es estad√≠sticamente robusto.\
-   **Limitaci√≥n:** el modelo explica solo una fracci√≥n peque√±a de la variaci√≥n ($16\%$).

------------------------------------------------------------------------

üìä **Conclusi√≥n**

La regresi√≥n simple muestra evidencia s√≥lida de que el d√≥lar influye en el oro de forma negativa.\
Sin embargo, la baja capacidad predictiva ($R^2$ bajo) implica que se necesitan otros factores (petr√≥leo, tasas de inter√©s, inflaci√≥n, shocks geopol√≠ticos) para construir un modelo predictivo m√°s fuerte.

**Cuadro resumen**

```{r}
library(gt)
#| label: simple-lm
lm_s <- lm(gold_ret ~ dollar_ret, data = s1)
broom::tidy(lm_s, conf.int = TRUE) |>
  gt() |>
  tab_header(title = "OLS (simple): coeficientes e IC 95%") |>
  fmt_num(c(estimate, std.error, statistic, p.value, conf.low, conf.high), dec = 6)

```

**Un cuadro mas completo**

```{r}
library(gt)

resumen <- broom::tidy(lm_s, conf.int = TRUE) |>
  mutate(
    sig = case_when(
      p.value < 0.01 ~ "***",
      p.value < 0.05 ~ "**",
      p.value < 0.1  ~ "*",
      TRUE ~ ""
    ),
    interpretacion = c(
      "Cuando el retorno del d√≥lar es 0, el oro sube ‚âà 0.66% en promedio",
      "Un aumento de 1% en el retorno del d√≥lar reduce el retorno del oro en ‚âà 1.09%"
    )
  )

gt(resumen) |>
  fmt_number(columns = c(estimate, std.error, statistic, p.value, conf.low, conf.high),
             decimals = 6, dec_mark = ",", sep_mark = ".") |>
  tab_header(title = "OLS (simple): coeficientes e interpretaci√≥n") |>
  cols_label(
    term = "Variable",
    estimate = "Estimador",
    std.error = "Error Est.",
    statistic = "t",
    p.value = "p-valor",
    conf.low = "IC 95% (Inf)",
    conf.high = "IC 95% (Sup)",
    sig = "Sig.",
    interpretacion = "Interpretaci√≥n"
  )

```

**¬øC√≥mo se ve gr√°ficamente esta relaci√≥n lineal?**

```{r}
# Gr√°fico de dispersi√≥n correcto
plot(d$dollar_ret, d$gold_ret,
     main = "Regresi√≥n lineal: Oro vs D√≥lar",
     xlab = "Rendimiento del d√≥lar",
     ylab = "Rendimiento del oro",
     pch = 19, col = "darkgray")

# Modelo consistente
modelo <- lm(gold_ret ~ dollar_ret, data = d)

# L√≠nea de regresi√≥n
abline(modelo, col = "blue", lwd = 2)


```

**Gr√°fico con ggplot**

```{r, warning=FALSE, message=FALSE}
s1 |> ggplot(aes(dollar_ret, gold_ret)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "lm", se = TRUE, linewidth = 0.9) +
  labs(x = "Retorno del D√≥lar (DXY)", y = "Retorno del Oro", title = "Regresi√≥n lineal simple") +
  theme_minimal()

```

**Diagnostico predictivo inicial**

```{r}
library(broom)
library(gt)

# Ajuste del modelo
lm_s <- lm(gold_ret ~ dollar_ret, data = d)

# Resumen del modelo
glance_tbl <- broom::glance(lm_s)

# Tabla con formateo
glance_tbl %>%
  gt() %>%
  tab_header(title = "Diagn√≥stico global (R¬≤, F, œÉ, AIC/BIC)") %>%
  fmt_number(
    columns = c(r.squared, adj.r.squared, sigma, statistic, p.value, AIC, BIC, logLik, deviance),
    decimals = 6,
    dec_mark = ",",
    sep_mark = "."
  )

```

```{r, echo=FALSE, message=FALSE, warning=FALSE}
tabla <- data.frame(
  Estad√≠stico = c("R¬≤", "R¬≤ ajustado", "œÉ (residual standard error)", 
                  "F (statistic)", "p-value (modelo)", 
                  "df (grados de libertad regresor)", "df.residual", "nobs",
                  "LogLik", "AIC", "BIC", "Deviance"),
  Valor = c(0.161, 0.155, 0.0341, 28.06, "< 0.0001", 
            1, 146, 148, 291.08, -576.16, -567.17, 0.1696),
  Interpretaci√≥n = c(
    "El modelo explica el 16.1% de la variaci√≥n en el retorno del oro a partir del retorno del d√≥lar.",
    "Similar al R¬≤, ajusta por el n√∫mero de predictores. Confirma que el modelo no est√° sobreajustado.",
    "El error t√≠pico de los residuos es ‚âà 3.4 puntos porcentuales en los retornos del oro. Indica la magnitud del error de predicci√≥n.",
    "Prueba de significancia global: el modelo como conjunto es significativo.",
    "Muy fuerte evidencia de que al menos un coeficiente (el retorno del d√≥lar) explica parte de la variaci√≥n en el oro.",
    "Solo hay un predictor (dollar_ret).",
    "Grados de libertad de los residuos (n - k - 1).",
    "Observaciones efectivas utilizadas.",
    "Valor de la funci√≥n de verosimilitud. Base para comparar modelos.",
    "Criterio de Akaike: m√°s bajo indica mejor ajuste relativo.",
    "Criterio de Bayes: penaliza m√°s por complejidad, √∫til en comparaci√≥n de modelos.",
    "Suma de residuos al cuadrado (varianza no explicada)."
  )
)

gt(tabla)

```

## Supuestos de OLS y diagn√≥sticos

-   **Linealidad**: Este supuesto implica que la relaci√≥n entre las variables independientes y la variable dependiente debe ser lineal. Si la relaci√≥n es no lineal, los resultados de la regresi√≥n (lineal) pueden ser poco confiables y conducir a interpretaciones err√≥neas sobre la relaci√≥n entre las variables.

-   **Normalidad**: El supuesto de normalidad establece que los **errores** de la regresi√≥n deben seguir una distribuci√≥n normal. ¬°Cuidado con esto!, los errores, no las variables. Cuando este supuesto se cumple, las pruebas de hip√≥tesis y los intervalos de confianza pueden interpretarse con mayor precisi√≥n. Si la normalidad no se cumple, los intervalos de confianza y las pruebas de hip√≥tesis pueden verse afectados, lo que puede conducir a conclusiones err√≥neas.

-   **Homocedasticidad**: Este supuesto implica que la varianza de los **errores** debe ser constante en todos los niveles de las variables predictoras. Cuando se viola este supuesto, se produce **heterocedasticidad**, lo que significa que la dispersi√≥n de los errores var√≠a en diferentes rangos de las variables predictoras. La presencia de heterocedasticidad puede distorsionar los intervalos de confianza y los valores p-value, lo que puede afectar la precisi√≥n de las pruebas de hip√≥tesis.

-   **Independencia**: El supuesto de independencia indica que los errores de la regresi√≥n no deben estar correlacionados entre s√≠. Si hay autocorrelaci√≥n presente, puede afectar la precisi√≥n de los coeficientes y las pruebas de hip√≥tesis, lo que lleva a conclusiones err√≥neas sobre la importancia de las variables predictoras. **¬øQu√© es la autocorrelaci√≥n?** la presencia de autocorrelaci√≥n en los residuos indica que **los errores del modelo muestran cierto patr√≥n sistem√°tico en su distribuci√≥n a lo largo del tiempo**. Recordad que los errores o residuos de un modelo de regresi√≥n deber√≠an distribuirse de manera aleatoria y seguir una distribuci√≥n normal con media cero y varianza constante.

```{r}
#| label: diag-plots
#| fig-cap: "Residuos vs ajustados (homocedasticidad y forma)"
aug <- broom::augment(lm_s)
aug |>
  ggplot(aes(.fitted, .resid)) +
  geom_hline(yintercept = 0, linetype = 2, color="gray50") +
  geom_point(alpha = 0.6) +
  labs(x="Ajustados", y="Residuos") + theme_minimal()

```

```{r}
#| label: diag-qq
#| fig-cap: "Normalidad: Q‚ÄìQ plot"
qq <- qqnorm(resid(lm_s), plot.it = FALSE)
tibble(x = qq$x, y = qq$y) |>
  ggplot(aes(x, y)) +
  geom_abline(slope = 1, intercept = 0, color="gray50") +
  geom_point(alpha = 0.6) + theme_minimal() +
  labs(x="Te√≥rico", y="Muestral")

```

```{r}
#| label: tests
# Pruebas formales
dw <- lmtest::dwtest(lm_s)      # autocorrelaci√≥n
bp <- lmtest::bptest(lm_s)      # heterocedasticidad (Breusch‚ÄìPagan)
sh <- shapiro.test(resid(lm_s)) # normalidad (muestras peque√±as)

tibble(
  prueba = c("Durbin‚ÄìWatson", "Breusch‚ÄìPagan", "Shapiro‚ÄìWilk"),
  estadistico = c(dw$statistic, bp$statistic, sh$statistic),
  p_value     = c(dw$p.value, bp$p.value, sh$p.value)
) |>
  gt() |> tab_header(title = "Pruebas de supuestos (simple)") |>
  fmt_num(c(estadistico, p_value), dec = 6)

```

```{r}
#| label: influence
#| fig-cap: "Puntos influyentes (Cook's D)"
cook <- cooks.distance(lm_s)
thr  <- 4/(nrow(s1) - 2 - 1) # umbral aproximado
tibble(i = seq_along(cook), cooksD = as.numeric(cook)) |>
  ggplot(aes(i, cooksD)) +
  geom_hline(yintercept = thr, color="firebrick", linetype = 2) +
  geom_point(alpha = 0.6) + theme_minimal() +
  labs(x="√çndice", y="Cook's D", subtitle=paste("Umbral ‚âà", round(thr, 4)))

```

‚Ä¢ Con 1 predictor, VIF = 1 trivialmente (no hay multicolinealidad).\

‚Ä¢ En series de tiempo, la autocorrelaci√≥n y heterocedasticidad son frecuentes. Lo importante es reportarlo y pasar a un flujo robusto fuera de muestra.

## An√°lisis Eploratorio de Datos (EDA)

```{r}
library(tidymodels)
library(tidyverse)
library(skimr)
library(DataExplorer)
library(ggpubr)
library(univariateML)
library(GGally)
library(doParallel)
skim(d)
```

**Datos faltantes**

```{r}
d %>% map_dbl(.f = function(x){sum(is.na(x))})
```

**Missing data**

```{r}
plot_missing(
  data    = d, 
  title   = "Porcentaje de valores ausentes",
  ggtheme = theme_bw(),
  theme_config = list(legend.position = "none")
)
```

**Distribuci√≥n o Densidad**

```{r}
p1 <- ggplot(data = d, aes(x = GOLD)) +
      geom_density(fill = "steelblue", alpha = 0.8) +
      geom_rug(alpha = 0.1) +
      scale_x_continuous(labels = scales::comma) +
      labs(title = "Distribuci√≥n original") +
      theme_bw() 

p2 <- ggplot(data = d, aes(x = sqrt(GOLD))) +
      geom_density(fill = "steelblue", alpha = 0.8) +
      geom_rug(alpha = 0.1) +
      scale_x_continuous(labels = scales::comma) +
      labs(title = "Transformaci√≥n ra√≠z cuadrada") +
      theme_bw()

p3 <- ggplot(data = d, aes(x = log(GOLD))) +
      geom_density(fill = "steelblue", alpha = 0.8) +
      geom_rug(alpha = 0.1) +
      scale_x_continuous(labels = scales::comma) +
      labs(title = "Transformaci√≥n logar√≠tmica") +
      theme_bw() 

ggarrange(p1, p2, p3, ncol = 1, align = "v")
```

**Varible ret**

```{r, message=FALSE, warning=FALSE}

p1 <- ggplot(data = d, aes(x = gold_ret)) +
      geom_density(fill = "steelblue", alpha = 0.8) +
      geom_rug(alpha = 0.1) +
      scale_x_continuous(labels = scales::comma) +
      labs(title = "Distribuci√≥n original") +
      theme_bw() 

p2 <- ggplot(data = d, aes(x = sqrt(gold_ret))) +
      geom_density(fill = "steelblue", alpha = 0.8) +
      geom_rug(alpha = 0.1) +
      scale_x_continuous(labels = scales::comma) +
      labs(title = "Transformaci√≥n ra√≠z cuadrada") +
      theme_bw()

p3 <- ggplot(data = d, aes(x = log(gold_ret))) +
      geom_density(fill = "steelblue", alpha = 0.8) +
      geom_rug(alpha = 0.1) +
      scale_x_continuous(labels = scales::comma) +
      labs(title = "Transformaci√≥n logar√≠tmica") +
      theme_bw() 

ggarrange(p1, p2, p3, ncol = 1, align = "v")
```

**Distribuci√≥n de variables continuas**

```{r}
plot_density(
  data    = d %>% select(-up_next),
  ncol    = 3,
  title   = "Distribuci√≥n variables continuas",
  ggtheme = theme_bw(),
  theme_config = list(
                  plot.title = element_text(size = 16, face = "bold"),
                  strip.text = element_text(colour = "black", size = 12, face = 2)
                 )
  )
```

**Plot de variables cualitativas**

```{r}
plot_bar(
  d,
  ncol    = 3,
  title   = "N√∫mero de observaciones por grupo",
  ggtheme = theme_bw(),
  theme_config = list(
                   plot.title = element_text(size = 16, face = "bold"),
                   strip.text = element_text(colour = "black", size = 12, face = 2),
                   legend.position = "none"
                  )
)
```

```{r}
#| label: eda
eda <- d |>
  select(gold_next_ret, dollar_ret, wti_ret, infl_yoy, ma6, ma12, rsi14) |>
  drop_na()

cor(eda, use="pairwise.complete.obs") |>
  as.data.frame() |> rownames_to_column("var") |> as_tibble() |>
  gt() |> tab_header(title="Correlaciones (Pearson)") |> fmt_num(everything(), dec=3)
```

# **Tidymodels**

![](images/Captura%20de%20pantalla%202025-09-10%20124819.png){fig-align="center"}

# **Preprocesamiento**

**rsample:** Creamos una divisi√≥n entre train y test

## Partici√≥n temporal y feature engineering (Recipes)

```{r, warning=FALSE, message=FALSE}
library(rsample)
library(recipes)

set.seed(123)
datos <- d |>
  select(date, gold_next_ret, dollar_ret, wti_ret, infl_yoy, ma6, ma12, rsi14) |>
  drop_na()

split <- initial_time_split(datos, prop = 0.80)
train <- training(split); test <- testing(split)

tibble(n_train=nrow(train), n_test=nrow(test),
       min_train=min(train$date), max_train=max(train$date),
       min_test=min(test$date),   max_test=max(test$date)) |>
  gt() |> tab_header(title="Partici√≥n temporal")

```

```{r}
print (split)
```

```{r}
library(recipes)
#| label: recipe
rec <- recipes::recipe(gold_next_ret ~ dollar_ret + wti_ret + infl_yoy + ma6 + ma12 + rsi14, data=train) |>
  step_zv(all_predictors()) |>
  step_normalize(all_numeric_predictors()) |>
  step_corr(all_numeric_predictors(), threshold = 0.95)

prep(rec)  # mostrar√° qu√© variables elimina por colinealidad (p.ej. ma12)


```

-   **Inputs**

    1 variable objetivo (`gold_next_ret`) y 6 predictores (los listados)

    **Training information**

    -   La receta ‚Äúaprendi√≥‚Äù usando **118 observaciones** de `train` y no encontr√≥ filas incompletas

    **Operations**

    -   **Zero variance**: no se elimin√≥ ninguna ( `<none>` ).

        **Centering and scaling**: se normalizaron todos los predictores num√©ricos.

        **Correlation filter on: `ma12`**: el filtro de correlaci√≥n **elimin√≥ `ma12`** por estar **muy correlacionada** (\|œÅ\| ‚â• 0.95) con otra(s) variable(s) ‚Äît√≠picamente con `ma6`, porque son medias m√≥viles muy parecidas.

        En otras palabras: **tu dise√±o final** para el modelo qued√≥ con los predictores normalizados y **sin `ma12`** (para evitar colinealidad).

## **Especificaci√≥n del modelo y engine (parsnip)**

```{r}
library(parsnip)

mod_lm <- linear_reg() |> set_engine("lm")
wf <- workflow() |> add_recipe(rec) |> add_model(mod_lm)
wf

```

**Ajuste, predicci√≥n y diagn√≥stico**

```{r}
#| label: fit-predict
fit_lm <- fit(wf, data = train)
preds  <- predict(fit_lm, new_data = test) |>
  bind_cols(test |> select(date, gold_next_ret))

preds |> slice_tail(n=8) |>
  gt() |> tab_header(title="Predicciones (√∫ltimas filas)") |>
  fmt_num(c(.pred, gold_next_ret), dec=6)
```

```{r}
#| label: fig-pred-real
#| fig-cap: "Test: Real vs Predicho"
preds |>
  ggplot(aes(gold_next_ret, .pred)) +
  geom_point(alpha=0.7) +
  geom_smooth(method="lm", se=FALSE, linewidth=0.9) +
  labs(x="Real", y="Predicho") + theme_minimal()
```

```{r}
#| label: resid-time
#| fig-cap: "Residuos en Test"
preds |>
  mutate(resid = gold_next_ret - .pred) |>
  ggplot(aes(date, resid)) +
  geom_hline(yintercept=0, linetype=2, color="gray50") +
  geom_line(linewidth=0.8, color="firebrick") +
  theme_minimal() + labs(x=NULL, y="Residual")

```

```{r}
#| label: engine-diagnostics
eng <- fit_lm |> extract_fit_engine()
broom::glance(eng) |>
  gt() |> tab_header(title="Resumen (engine lm)") |>
  fmt_num(c(r.squared, adj.r.squared, sigma, AIC, BIC, statistic, p.value), dec=6)

lmtest::dwtest(eng); lmtest::bptest(eng); performance::check_model(eng)

```

## M√©tricas y validaci√≥n temporal

```{r}
#| label: metrics
yardstick::metrics(preds, truth = gold_next_ret, estimate = .pred) |>
  gt() |> tab_header(title="M√©tricas en Test") |> fmt_num(.estimate, dec=6)

```

```{r}
#| label: rolling-origin
set.seed(123)
rs <- rolling_origin(
  datos,
  initial = 60, assess = 12, skip = 6, cumulative = TRUE
)
res_cv <- fit_resamples(wf, resamples = rs, control = control_resamples(save_pred = TRUE))
collect_metrics(res_cv) |>
  gt() |> tab_header(title="CV temporal (promedios)") |> fmt_num(c(mean, std_err), dec=6)

```
